{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"catena a Python Utility for Submitting Work to a SLURM Cluster catena is a Python library for interacting with SLURM through the REST API. In particular, the library is focused on the submission of jobs to a SLURM cluster, either locally or remotely, but can be extended to other schedulers with a suitable API. \ud83d\udcdd Note : Currently only works when running locally on a SLURM HPC \ud83d\udccb Key Features Provides 'job' classes that allow for work to be orchestrated through SLURM, programatically in Python Defines schemas with sensible defaults and validators for SLURM /job/submit request Affords end-users the ability to orchestrate multiple jobs in various programming languages using Job Manifests Allows building and running pipelines of inter-dependent jobs (DAGs) of various programing languages to be run on a SLURM HPC using Job Pipelines [] Provides ability to share and cache results of jobs between almost any programming language \ud83d\udcdd Note : This project is still under development. Quickstart Clone the repository and try out some examples \ud83d\udccd Move into the repo and load anaconda3/2021.05 (or your favourite version, as long as python >= 3.6) $ cd catena/examples $ module load anaconda3/2021.05 \ud83d\udccd Install all requirements for catena $ pip3 install --user -r requirements.txt ---> 100% TODO Local job submission single script any language programatically in Python Local submission of many job sripts of various languages using Job Manifests Unit test all components involved in above Local submission of many interdependent job scripts represented as a DAG using Job Pipelines Build out custom loggers using loguru (e.g. job monitor, verbose vs. silent/to file) Unit test all components involved in above Setup GitHub actions for CI/CD Extend all of the above to remote job execution: will require ability to mount remote files possibly using a custom variation on squashfs mixed with gRPC.","title":"Home"},{"location":"#catena-a-python-utility-for-submitting-work-to-a-slurm-cluster","text":"catena is a Python library for interacting with SLURM through the REST API. In particular, the library is focused on the submission of jobs to a SLURM cluster, either locally or remotely, but can be extended to other schedulers with a suitable API. \ud83d\udcdd Note : Currently only works when running locally on a SLURM HPC","title":"catena a Python Utility for Submitting Work to a SLURM Cluster"},{"location":"#key-features","text":"Provides 'job' classes that allow for work to be orchestrated through SLURM, programatically in Python Defines schemas with sensible defaults and validators for SLURM /job/submit request Affords end-users the ability to orchestrate multiple jobs in various programming languages using Job Manifests Allows building and running pipelines of inter-dependent jobs (DAGs) of various programing languages to be run on a SLURM HPC using Job Pipelines [] Provides ability to share and cache results of jobs between almost any programming language \ud83d\udcdd Note : This project is still under development.","title":"\ud83d\udccb Key Features"},{"location":"#quickstart","text":"Clone the repository and try out some examples \ud83d\udccd Move into the repo and load anaconda3/2021.05 (or your favourite version, as long as python >= 3.6) $ cd catena/examples $ module load anaconda3/2021.05 \ud83d\udccd Install all requirements for catena $ pip3 install --user -r requirements.txt ---> 100%","title":"Quickstart"},{"location":"#todo","text":"Local job submission single script any language programatically in Python Local submission of many job sripts of various languages using Job Manifests Unit test all components involved in above Local submission of many interdependent job scripts represented as a DAG using Job Pipelines Build out custom loggers using loguru (e.g. job monitor, verbose vs. silent/to file) Unit test all components involved in above Setup GitHub actions for CI/CD Extend all of the above to remote job execution: will require ability to mount remote files possibly using a custom variation on squashfs mixed with gRPC.","title":"TODO"},{"location":"manifests/","text":"Job Manifests Job manifests are YAML files that allows you to organize instructions for submitting any number of jobs or scripts of various languages to SLURM for scheduling within the cluster. Structure of a Job Manifest At the top of the manifest we specify the schema version and a cluster profile. The cluster profile provides the name of the SLURM cluster to which the jobs should be submitted. The configuration is specfied in the users HOME directory in $HOME/.catena/conf.yml . The schema for this can be seen here After that, they are comprised of two sections: job_options ( Optional ): Section under which job option blocks can be added. Each of these named configuration sets defines SLURM sbatch options and environment modules that should be loaded for a given job. A single option block can be applied to a single job, or multiple jobs that run different scripts, but have similar requirements. These named configuration sets are referenced using the built-in & and * constructors in YAML. jobs ( Required ): Section under which jobs to run are defined. The most basic job manifest is for a single job, with the optional job_options section excluded: --- jobs : - matlab_test : job_script : \"/path/to/matlab/script/to/run.m\" job : env_modules : - matlab/96 standard_out : '/path/to/stdout/file.out' standard_error : '/path/to/stderr/file.err' cpus_per_task : 2 tasks : 1 memory_per_node : '2GB' This manifest will submit a job with the name matlab_test to the SLURM scheduler, requesting a single node with 2 cores and 2GB of RAM. The job will run a MATLAB script, which exists at the full absolute path job_script . In this instance a version of MATLAB is required to run the job_script provided and, therefore, under env_modules we add matlab/96 to the list of environment modules to be loaded. Each job follows the general structure: --- jobs : - job_name1 : job_sript : \"path to script to be run\" job : ...job options... - job_name2 : job_sript : \"path to script to be run\" job : ...job options... Any number of jobs can be defined under the jobs section. --- version : 1.0 cluster_profile : 'my_slurm_cluster1' jobs : - job_name1 : job_sript : \"path to script to be run\" job : ...job1 options... - job_name2 : job_sript : \"path to script to be run\" job : ...job2 options... ... ... \ud83d\udece\ufe0f Important : The configuration properties that may be defined within a job option block are controlled by the [ SlurmSubmit (models/slurm_job_schemas.md#slurm_submit) schema. In addition to SLURM sbatch options, a given job definition is comprised as many so called Extra Options . These are not SLURM options but are also used in initializing a Job object to be submitted to a SLURM cluster. Here are some key points about defining job options for a job definition: Job options can be defined globally under job_options and referenced within a given job definition using anchors/aliases under the job key They can be defined locally within a given job definition the job key within a given job definition should be reserved for global job options defined under job_options All job options that can be defined globally can also be defined locally Job options defined locally will take precedence over global job options defined under the job key Useful for having a shared set of job settings across multiple jobs while still being able to define local job settings that differ from job to job. Defining Reusable (Global) Job Options: job_options The basic manifest provided for a MATLAB job could also be re-written using the job_options section as follows: --- job_options : matlab : &matlab env_modules : - matlab/96 standard_out : '/path/to/stdout/file.out' standard_error : '/path/to/stderr/file.err' cpus_per_task : 2 tasks : 1 memory_per_node : '2GB' jobs : matlab_test : job_script : \"/path/to/matlab/script/to/run.m\" job : *matlab Here we have defined a job option block using an anchor: &matlab . Using anchors provides a means of freely referencing this block elsewhere within your manifest by calling it with the corresponding alias, *matlab , as shown. With this in mind, consider a case where we'd like to run a series of jobs in either MATLAB or Python. In this instance the job_options section provides a means of better organizing our manifest: --- job_options : matlab : &matlab env_modules : - matlab/96 standard_out : '/path/to/stdout/file.out' standard_error : '/path/to/stderr/file.err' cpus_per_task : 2 tasks : 1 memory_per_node : '2GB' python : &python env_modules : - anaconda3/2021.05 standard_out : '/path/to/stdout/file.out' standard_error : '/path/to/stderr/file.err' cpus_per_task : 2 tasks : 1 memory_per_node : '2GB' jobs : - matlab_job1 : job_script : \"/path/to/matlab/script/to/run.m\" job : *matlab - python_job1 : job_script : \"/path/to/python/script/to/run1.py\" job : *python - python_job2 : job_script : \"/path/to/python/script/to/run2.py\" job : *python Which is equivalent to --- version : 1.0 cluster_profile : 'my_slurm_cluster' jobs : - matlab_job1 : job_script : \"/path/to/matlab/script/to/run.m\" job : env_modules : - matlab/96 standard_out : '/path/to/stdout/file.out' standard_error : '/path/to/stderr/file.err' cpus_per_task : 2 tasks : 1 memory_per_node : '2GB' - python_job1 : job_script : \"/path/to/python/script/to/run1.py\" job : env_modules : - anaconda3/2021.05 standard_out : '/path/to/stdout/file.out' standard_error : '/path/to/stderr/file.err' cpus_per_task : 2 tasks : 1 memory_per_node : '2GB' - python_job2 : job_script : \"/path/to/python/script/to/run2.py\" job : env_modules : - anaconda3/2021.05 standard_out : '/path/to/stdout/file.out' standard_error : '/path/to/stderr/file.err' cpus_per_task : 2 tasks : 1 memory_per_node : '2GB' Cleary, when the number of jobs and options begins to grow this could become more cumbersome to read. The following is an example of a simple job manifest Using the !include Constructor The !include constructor allows you to include options or blocks from other external YML files, given the path. For instance, given three YAML files in the same directory: manifest.yml : the main manifest job_opts1.yml : manifest containing global job options jobs.yml : manifest containing job definitions The !include constructor can be used for defining either job_options or jobs or both. For example given two YML files in the same directory, manifest.yaml and jobs.yaml : manifest.yaml --- job_options : - matlab : &matlab env_modules : - matlab/96 standard_out : '~/man_matlab.out' standard_error : '~/man_matlab.err' cpus_per_task : 2 tasks : 1 memory_per_node : '2GB' python : &python env_modules : - anaconda3/2021.05 standard_out : '~/man_python.out' standard_error : '~/man_python.err' cpus_per_task : 2 tasks : 1 memory_per_node : '2GB' jobs : - !include jobs.yaml jobs.yaml --- jobs : - matlab_job1 : job_script : \"/path/to/matlab/script/to/run.m\" job : *matlab - python_job1 : job_script : \"/path/to/python/script/to/run1.py\" job : *python - python_job2 : job_script : \"/path/to/python/script/to/run2.py\" job : *python This would be equivalent to the explicit manifest previously shown. The following example looks at this exact type of application. \ud83d\udece\ufe0f Important : Any number of include statements can be listed for referencing job_options and/or jobs from external YAML files. For instance, the Python and MATLAB job definitions were split into two files matlab_jobs.yaml and python_jobs.yaml . Then, they could be included like this: jobs : - !include matlab_jobs.yaml - !include python_jobs.yaml \ud83d\udece\ufe0f Important : The !include constructor and global job_options of a manifest can be used separately or combined to better organize more complex workloads. \ud83d\udece\ufe0f Important : When global job_options are included from external YML files and the global options are tagged with anchors(&), these options can be referenced by there corresponding alias (*). For instance, given the following 2 external YML files and a main manifest: One external YML files for defining global job options for matlab jobs: matlab_opts.yml --- job_options : - matlab : &matlab env_modules : - matlab/96 standard_out : '~/man_matlab.out' standard_error : '~/man_matlab.err' cpus_per_task : 2 tasks : 1 memory_per_node : '2GB' Another listing job definitions that alias the &matlab anchor matlab_jobs.yml --- jobs : - matlab_job1 : job_script : \"/path/to/matlab/script/to/run.m\" job : *matlab Then, using the !include constructor, the main manifest would be: manifest.yml --- job_options : - !include matlab_opts.yml jobs : - !include matlab_jobs.yml Or without using the !include constructor, the following main manifest would be valid as well: manifest.yml --- job_options : - !include matlab_opts.yml jobs : - matlab_job1 : job_script : \"/path/to/matlab/script/to/run.m\" job : *matlab Job Manifests Best Practices Using the !include constructor complex manifests can be organized into multiple YML files. For advanced job manifests involving multiple YAML files, it is good practice to keep things organized and make your manifests easy to navigate. Here is a sample manifest directory. \ud83d\udcdd Note : Any number of directories can be created and referenced within the main manifest root directory (i.e the directory container the main manifest to be run). The following example demonstrates how this setup can be used in practice. It also serves to demonstrate how relatives paths can be used to define job_options that correspond to paths, which is the subject of the following section. Understanding the Context in Which the Manifest is Run So far in the toy examples shown, not much attention has been given to the path definitions within job manifests and how they are resolved. In particular, it is generally useful to use relative paths to clean up a manifest and reduce the verbosity. \ud83d\udece\ufe0f Important : When definining paths within any manifest, all paths should be taken relative to the main manifest root directory : In addition to be able to define relative paths, the ~ expression is also valid and is expanded to the full absolute path of the home directory for the user calling SlurmJob or running a manifest. Ultimately, all paths defined within a manifest or SlurmJob are expanded to there absolute form. \ud83d\udcdd Note : expansion of paths defined within a given job definition (including any job options) is performed when validating the inputs to SlurmJob (i.e, using Pydantic validators in both the SlurmSubmit and the JobOptions schemas) Submitting a Manifest Currently, the Manifest object can be invoked by calling the catena module directly and providing the path to a manifest to be run. $ python3 -m catena /path/to/my/manifest.yaml \ud83d\udcbb Submitted job: 300205 \ud83d\udcbb Submitted job: 300206 \ud83d\udcbb Submitted job: 300207 \ud83d\udcbb Submitted job: 300208 \ud83d\udcdd Note : Currently not packaged.","title":"Job Manifests"},{"location":"manifests/#job-manifests","text":"Job manifests are YAML files that allows you to organize instructions for submitting any number of jobs or scripts of various languages to SLURM for scheduling within the cluster.","title":"Job Manifests"},{"location":"manifests/#structure-of-a-job-manifest","text":"At the top of the manifest we specify the schema version and a cluster profile. The cluster profile provides the name of the SLURM cluster to which the jobs should be submitted. The configuration is specfied in the users HOME directory in $HOME/.catena/conf.yml . The schema for this can be seen here After that, they are comprised of two sections: job_options ( Optional ): Section under which job option blocks can be added. Each of these named configuration sets defines SLURM sbatch options and environment modules that should be loaded for a given job. A single option block can be applied to a single job, or multiple jobs that run different scripts, but have similar requirements. These named configuration sets are referenced using the built-in & and * constructors in YAML. jobs ( Required ): Section under which jobs to run are defined. The most basic job manifest is for a single job, with the optional job_options section excluded: --- jobs : - matlab_test : job_script : \"/path/to/matlab/script/to/run.m\" job : env_modules : - matlab/96 standard_out : '/path/to/stdout/file.out' standard_error : '/path/to/stderr/file.err' cpus_per_task : 2 tasks : 1 memory_per_node : '2GB' This manifest will submit a job with the name matlab_test to the SLURM scheduler, requesting a single node with 2 cores and 2GB of RAM. The job will run a MATLAB script, which exists at the full absolute path job_script . In this instance a version of MATLAB is required to run the job_script provided and, therefore, under env_modules we add matlab/96 to the list of environment modules to be loaded. Each job follows the general structure: --- jobs : - job_name1 : job_sript : \"path to script to be run\" job : ...job options... - job_name2 : job_sript : \"path to script to be run\" job : ...job options... Any number of jobs can be defined under the jobs section. --- version : 1.0 cluster_profile : 'my_slurm_cluster1' jobs : - job_name1 : job_sript : \"path to script to be run\" job : ...job1 options... - job_name2 : job_sript : \"path to script to be run\" job : ...job2 options... ... ... \ud83d\udece\ufe0f Important : The configuration properties that may be defined within a job option block are controlled by the [ SlurmSubmit (models/slurm_job_schemas.md#slurm_submit) schema. In addition to SLURM sbatch options, a given job definition is comprised as many so called Extra Options . These are not SLURM options but are also used in initializing a Job object to be submitted to a SLURM cluster. Here are some key points about defining job options for a job definition: Job options can be defined globally under job_options and referenced within a given job definition using anchors/aliases under the job key They can be defined locally within a given job definition the job key within a given job definition should be reserved for global job options defined under job_options All job options that can be defined globally can also be defined locally Job options defined locally will take precedence over global job options defined under the job key Useful for having a shared set of job settings across multiple jobs while still being able to define local job settings that differ from job to job.","title":"Structure of a Job Manifest"},{"location":"manifests/#defining-reusable-global-job-options-job_options","text":"The basic manifest provided for a MATLAB job could also be re-written using the job_options section as follows: --- job_options : matlab : &matlab env_modules : - matlab/96 standard_out : '/path/to/stdout/file.out' standard_error : '/path/to/stderr/file.err' cpus_per_task : 2 tasks : 1 memory_per_node : '2GB' jobs : matlab_test : job_script : \"/path/to/matlab/script/to/run.m\" job : *matlab Here we have defined a job option block using an anchor: &matlab . Using anchors provides a means of freely referencing this block elsewhere within your manifest by calling it with the corresponding alias, *matlab , as shown. With this in mind, consider a case where we'd like to run a series of jobs in either MATLAB or Python. In this instance the job_options section provides a means of better organizing our manifest: --- job_options : matlab : &matlab env_modules : - matlab/96 standard_out : '/path/to/stdout/file.out' standard_error : '/path/to/stderr/file.err' cpus_per_task : 2 tasks : 1 memory_per_node : '2GB' python : &python env_modules : - anaconda3/2021.05 standard_out : '/path/to/stdout/file.out' standard_error : '/path/to/stderr/file.err' cpus_per_task : 2 tasks : 1 memory_per_node : '2GB' jobs : - matlab_job1 : job_script : \"/path/to/matlab/script/to/run.m\" job : *matlab - python_job1 : job_script : \"/path/to/python/script/to/run1.py\" job : *python - python_job2 : job_script : \"/path/to/python/script/to/run2.py\" job : *python Which is equivalent to --- version : 1.0 cluster_profile : 'my_slurm_cluster' jobs : - matlab_job1 : job_script : \"/path/to/matlab/script/to/run.m\" job : env_modules : - matlab/96 standard_out : '/path/to/stdout/file.out' standard_error : '/path/to/stderr/file.err' cpus_per_task : 2 tasks : 1 memory_per_node : '2GB' - python_job1 : job_script : \"/path/to/python/script/to/run1.py\" job : env_modules : - anaconda3/2021.05 standard_out : '/path/to/stdout/file.out' standard_error : '/path/to/stderr/file.err' cpus_per_task : 2 tasks : 1 memory_per_node : '2GB' - python_job2 : job_script : \"/path/to/python/script/to/run2.py\" job : env_modules : - anaconda3/2021.05 standard_out : '/path/to/stdout/file.out' standard_error : '/path/to/stderr/file.err' cpus_per_task : 2 tasks : 1 memory_per_node : '2GB' Cleary, when the number of jobs and options begins to grow this could become more cumbersome to read. The following is an example of a simple job manifest","title":"Defining Reusable (Global) Job Options: job_options"},{"location":"manifests/#using-the-include-constructor","text":"The !include constructor allows you to include options or blocks from other external YML files, given the path. For instance, given three YAML files in the same directory: manifest.yml : the main manifest job_opts1.yml : manifest containing global job options jobs.yml : manifest containing job definitions The !include constructor can be used for defining either job_options or jobs or both. For example given two YML files in the same directory, manifest.yaml and jobs.yaml : manifest.yaml --- job_options : - matlab : &matlab env_modules : - matlab/96 standard_out : '~/man_matlab.out' standard_error : '~/man_matlab.err' cpus_per_task : 2 tasks : 1 memory_per_node : '2GB' python : &python env_modules : - anaconda3/2021.05 standard_out : '~/man_python.out' standard_error : '~/man_python.err' cpus_per_task : 2 tasks : 1 memory_per_node : '2GB' jobs : - !include jobs.yaml jobs.yaml --- jobs : - matlab_job1 : job_script : \"/path/to/matlab/script/to/run.m\" job : *matlab - python_job1 : job_script : \"/path/to/python/script/to/run1.py\" job : *python - python_job2 : job_script : \"/path/to/python/script/to/run2.py\" job : *python This would be equivalent to the explicit manifest previously shown. The following example looks at this exact type of application. \ud83d\udece\ufe0f Important : Any number of include statements can be listed for referencing job_options and/or jobs from external YAML files. For instance, the Python and MATLAB job definitions were split into two files matlab_jobs.yaml and python_jobs.yaml . Then, they could be included like this: jobs : - !include matlab_jobs.yaml - !include python_jobs.yaml \ud83d\udece\ufe0f Important : The !include constructor and global job_options of a manifest can be used separately or combined to better organize more complex workloads. \ud83d\udece\ufe0f Important : When global job_options are included from external YML files and the global options are tagged with anchors(&), these options can be referenced by there corresponding alias (*). For instance, given the following 2 external YML files and a main manifest: One external YML files for defining global job options for matlab jobs: matlab_opts.yml --- job_options : - matlab : &matlab env_modules : - matlab/96 standard_out : '~/man_matlab.out' standard_error : '~/man_matlab.err' cpus_per_task : 2 tasks : 1 memory_per_node : '2GB' Another listing job definitions that alias the &matlab anchor matlab_jobs.yml --- jobs : - matlab_job1 : job_script : \"/path/to/matlab/script/to/run.m\" job : *matlab Then, using the !include constructor, the main manifest would be: manifest.yml --- job_options : - !include matlab_opts.yml jobs : - !include matlab_jobs.yml Or without using the !include constructor, the following main manifest would be valid as well: manifest.yml --- job_options : - !include matlab_opts.yml jobs : - matlab_job1 : job_script : \"/path/to/matlab/script/to/run.m\" job : *matlab","title":"Using the !include Constructor"},{"location":"manifests/#job-manifests-best-practices","text":"Using the !include constructor complex manifests can be organized into multiple YML files. For advanced job manifests involving multiple YAML files, it is good practice to keep things organized and make your manifests easy to navigate. Here is a sample manifest directory. \ud83d\udcdd Note : Any number of directories can be created and referenced within the main manifest root directory (i.e the directory container the main manifest to be run). The following example demonstrates how this setup can be used in practice. It also serves to demonstrate how relatives paths can be used to define job_options that correspond to paths, which is the subject of the following section.","title":"Job Manifests Best Practices"},{"location":"manifests/#understanding-the-context-in-which-the-manifest-is-run","text":"So far in the toy examples shown, not much attention has been given to the path definitions within job manifests and how they are resolved. In particular, it is generally useful to use relative paths to clean up a manifest and reduce the verbosity. \ud83d\udece\ufe0f Important : When definining paths within any manifest, all paths should be taken relative to the main manifest root directory : In addition to be able to define relative paths, the ~ expression is also valid and is expanded to the full absolute path of the home directory for the user calling SlurmJob or running a manifest. Ultimately, all paths defined within a manifest or SlurmJob are expanded to there absolute form. \ud83d\udcdd Note : expansion of paths defined within a given job definition (including any job options) is performed when validating the inputs to SlurmJob (i.e, using Pydantic validators in both the SlurmSubmit and the JobOptions schemas)","title":"Understanding the Context in Which the Manifest is Run"},{"location":"manifests/#submitting-a-manifest","text":"Currently, the Manifest object can be invoked by calling the catena module directly and providing the path to a manifest to be run. $ python3 -m catena /path/to/my/manifest.yaml \ud83d\udcbb Submitted job: 300205 \ud83d\udcbb Submitted job: 300206 \ud83d\udcbb Submitted job: 300207 \ud83d\udcbb Submitted job: 300208 \ud83d\udcdd Note : Currently not packaged.","title":"Submitting a Manifest"},{"location":"examples/example1/","text":"Example 1 - Using SLURMRESTJob to Submit Job Locally A first example to show how the SLURMRESTJob object can be used The **kwargs for SLURMRESTJob can be found listed the SlurmSubmit schema. This consists of all possible the SLURM SBATCH options, of which only a few are of interest in most cases. Additionally, SlurmJob has external or extra options . These are options used to specify a given job definition, but that are not SLURM sbatch options. In this example, a SlurmJob object in initialized with the following configuration: name : the name of the job once submitted to the SLURM scheduler will be slurmjobs_example1 job_script : path to script to be submitted as a job (when using relative paths upon invoking a SlurmJob object, the paths should be relative to the script's path that invokes SlurmJob .) env_extra : a dictionary, where they keys are the environment variable name to be set and the values are the corresponding values to assign to the associated key/environment variable. There are some caveats that allow appending, prepending of replacing a given environment variable if it already exists within the local environment that are discussed below standard_out : path to write stdout to file - notice in the example that it is acceptable to use ~ to specify the $HOME directory path of the current user standard_error path to write stderr to file - again the ~ is used tasks : number of tasks for SLURM to run cpus_per_task : number of CPUs to assign per task (total CPUs = tasks * cpus_per_task) memory_per_node : total memory to request for SLURM per node (default number of nodes requested is 1, unless specified otherwise) env_modules : list of strings with the names of environment modules to be loaded when running job_script (this is equivalent to executing module load <module> for each module before running job_script ). In particular this example runs a Golang binary, which prints 'Hello World!' unless an environment variable NAME is defined in the local environment. \ud83d\udece\ufe0f Important : a job_script without an extension is assumed to be a compiled binary and is run as such. This allows catena to extend beyond scripting languages to compiled binaries \ud83d\udece\ufe0f Important : catena attempts to be as language-agnostic as possible when it comes to what can be used for defining a Job object such as SlurmJob To set/unset environment variables in a bash shell: // To set the NAME environment variable locally $ export NAME = 'my name' // To unset the NAME environment variable locally $ unset NAME Appending, Prepending and Replacing Local Environment Variables: env_extra The example demonstrates the use of the env_extra kwarg in SlurmJob , using 'Christopher' as the name. You can change this in the script to your own name. There are a couple caveats with how the values in the env_extra dict are treated, where each keys are the name of the environment variables and the values are the corresponding values. To prepend your value to an existing value for a given environment variable append your value with : To append your value to an existing value for a given environment variable prepend your value with : To replace an existing value with your value for a given environment variable neither prepend or append your value with : \ud83d\udcdd Note : for (1) and (2) if the variable does not exist in your local environment than it will just set it to that default value. \ud83d\udcdd Note : rich is a great library for nicely printing things to the console. The inspect method is used here to expose what the class looks like and what it contains once defined. The code for this example is include in the repo at examples/0_simple_slurm_job/slurm_job1.py along with example scripts of various languages in examples/scripts . Running the Example from the Cloned Repository See a Jupyter Notebook code sample for this example here if you're not interested in runnning it yourself \ud83d\udccd Move into the example directory and load anaconda3/2021.05 (or your favourite version, as long as python >= 3.6) $ cd examples/0_simple_slurm_job/ $ module load anaconda3/2021.05 \ud83d\udccd Execute the code // to view job object before submitting a job $ python3 slurm_job1.py // to view job object before and after submitting a job $ python3 slurm_job1.py -s \ud83d\udccd View results of job output // View results of example $ cat ~/go_hello_world.out \ud83d\udcdd Note : To run this script and have it submit a job, you should add the -s flag e.g: python3 slurm_job1.py -s","title":"Running the Example"},{"location":"examples/example1/#example-1-using-slurmrestjob-to-submit-job-locally","text":"A first example to show how the SLURMRESTJob object can be used The **kwargs for SLURMRESTJob can be found listed the SlurmSubmit schema. This consists of all possible the SLURM SBATCH options, of which only a few are of interest in most cases. Additionally, SlurmJob has external or extra options . These are options used to specify a given job definition, but that are not SLURM sbatch options. In this example, a SlurmJob object in initialized with the following configuration: name : the name of the job once submitted to the SLURM scheduler will be slurmjobs_example1 job_script : path to script to be submitted as a job (when using relative paths upon invoking a SlurmJob object, the paths should be relative to the script's path that invokes SlurmJob .) env_extra : a dictionary, where they keys are the environment variable name to be set and the values are the corresponding values to assign to the associated key/environment variable. There are some caveats that allow appending, prepending of replacing a given environment variable if it already exists within the local environment that are discussed below standard_out : path to write stdout to file - notice in the example that it is acceptable to use ~ to specify the $HOME directory path of the current user standard_error path to write stderr to file - again the ~ is used tasks : number of tasks for SLURM to run cpus_per_task : number of CPUs to assign per task (total CPUs = tasks * cpus_per_task) memory_per_node : total memory to request for SLURM per node (default number of nodes requested is 1, unless specified otherwise) env_modules : list of strings with the names of environment modules to be loaded when running job_script (this is equivalent to executing module load <module> for each module before running job_script ). In particular this example runs a Golang binary, which prints 'Hello World!' unless an environment variable NAME is defined in the local environment. \ud83d\udece\ufe0f Important : a job_script without an extension is assumed to be a compiled binary and is run as such. This allows catena to extend beyond scripting languages to compiled binaries \ud83d\udece\ufe0f Important : catena attempts to be as language-agnostic as possible when it comes to what can be used for defining a Job object such as SlurmJob To set/unset environment variables in a bash shell: // To set the NAME environment variable locally $ export NAME = 'my name' // To unset the NAME environment variable locally $ unset NAME","title":"Example 1 - Using SLURMRESTJob to Submit Job Locally"},{"location":"examples/example1/#appending-prepending-and-replacing-local-environment-variables-env_extra","text":"The example demonstrates the use of the env_extra kwarg in SlurmJob , using 'Christopher' as the name. You can change this in the script to your own name. There are a couple caveats with how the values in the env_extra dict are treated, where each keys are the name of the environment variables and the values are the corresponding values. To prepend your value to an existing value for a given environment variable append your value with : To append your value to an existing value for a given environment variable prepend your value with : To replace an existing value with your value for a given environment variable neither prepend or append your value with : \ud83d\udcdd Note : for (1) and (2) if the variable does not exist in your local environment than it will just set it to that default value. \ud83d\udcdd Note : rich is a great library for nicely printing things to the console. The inspect method is used here to expose what the class looks like and what it contains once defined. The code for this example is include in the repo at examples/0_simple_slurm_job/slurm_job1.py along with example scripts of various languages in examples/scripts .","title":" Appending, Prepending and Replacing Local Environment Variables: env_extra"},{"location":"examples/example1/#running-the-example-from-the-cloned-repository","text":"See a Jupyter Notebook code sample for this example here if you're not interested in runnning it yourself \ud83d\udccd Move into the example directory and load anaconda3/2021.05 (or your favourite version, as long as python >= 3.6) $ cd examples/0_simple_slurm_job/ $ module load anaconda3/2021.05 \ud83d\udccd Execute the code // to view job object before submitting a job $ python3 slurm_job1.py // to view job object before and after submitting a job $ python3 slurm_job1.py -s \ud83d\udccd View results of job output // View results of example $ cat ~/go_hello_world.out \ud83d\udcdd Note : To run this script and have it submit a job, you should add the -s flag e.g: python3 slurm_job1.py -s","title":"Running the Example from the Cloned Repository"},{"location":"examples/example2a/","text":"Example 2a - Using Job Manifests to Organize Workloads This example introduces the concept of Job Manifests , which are YAML files that can be used to specify the configuration of multiple SLURM jobs in an easily readible and re-usable way. As an introduction, a basic manifest is provided in examples/1_job_manifests/sample_manifests/basic_manifest.yaml basic_manifest.yaml --- version : 1.0 cluster_profile : 'my_slurm_cluster1' job_options : - python : &python env_modules : - python/3.10.7 standard_out : '~/man_python.out' standard_error : '~/man_python.err' cpus_per_task : 2 tasks : 1 memory_per_node : '2GB' - R : &r env_modules : - R/4.2.1 standard_out : '~/man_python.out' standard_error : '~/man_python.err' cpus_per_task : 2 tasks : 1 memory_per_node : '2GB' - julia : &julia env_modules : - julia/1.8.1 standard_out : '~/man_julia.out' standard_error : '~/man_julia.err' cpus_per_task : 2 tasks : 1 memory_per_node : '2GB' jobs : - python_test : job_script : \"../../scripts/test.py\" job : *python - r_test : job_script : \"../../scripts/test.r\" job : *r - julia_test : job_script : \"../../scripts/test.jl\" job : *julia This example will submit four jobs of four different languages, MATLAB, Python, R, and Julia. Theoretically, SLURMRESTJob should work for almost any language job script, including compiled binaries. Running the Example from the Cloned Repository See a Jupyter Notebook code sample for this example here if you're not interested in runnning it yourself \ud83d\udccd Move into examples directory and load anaconda3/2021.05 (or your favourite version, as long as python >= 3.6) $ cd slurmjobs/examples/1_job_manifests $ module load anaconda3/2021.05 \ud83d\udccd Execute the code // to view job object before submitting a job $ python3 0_basic_manifest.py // to view job object before and after submitting a job $ python3 0_basic_manifest.py -s","title":"Running the Example"},{"location":"examples/example2a/#example-2a-using-job-manifests-to-organize-workloads","text":"This example introduces the concept of Job Manifests , which are YAML files that can be used to specify the configuration of multiple SLURM jobs in an easily readible and re-usable way. As an introduction, a basic manifest is provided in examples/1_job_manifests/sample_manifests/basic_manifest.yaml basic_manifest.yaml --- version : 1.0 cluster_profile : 'my_slurm_cluster1' job_options : - python : &python env_modules : - python/3.10.7 standard_out : '~/man_python.out' standard_error : '~/man_python.err' cpus_per_task : 2 tasks : 1 memory_per_node : '2GB' - R : &r env_modules : - R/4.2.1 standard_out : '~/man_python.out' standard_error : '~/man_python.err' cpus_per_task : 2 tasks : 1 memory_per_node : '2GB' - julia : &julia env_modules : - julia/1.8.1 standard_out : '~/man_julia.out' standard_error : '~/man_julia.err' cpus_per_task : 2 tasks : 1 memory_per_node : '2GB' jobs : - python_test : job_script : \"../../scripts/test.py\" job : *python - r_test : job_script : \"../../scripts/test.r\" job : *r - julia_test : job_script : \"../../scripts/test.jl\" job : *julia This example will submit four jobs of four different languages, MATLAB, Python, R, and Julia. Theoretically, SLURMRESTJob should work for almost any language job script, including compiled binaries.","title":"Example 2a - Using Job Manifests to Organize Workloads"},{"location":"examples/example2a/#running-the-example-from-the-cloned-repository","text":"See a Jupyter Notebook code sample for this example here if you're not interested in runnning it yourself \ud83d\udccd Move into examples directory and load anaconda3/2021.05 (or your favourite version, as long as python >= 3.6) $ cd slurmjobs/examples/1_job_manifests $ module load anaconda3/2021.05 \ud83d\udccd Execute the code // to view job object before submitting a job $ python3 0_basic_manifest.py // to view job object before and after submitting a job $ python3 0_basic_manifest.py -s","title":"Running the Example from the Cloned Repository"},{"location":"examples/example2b/","text":"Example 2b - Using the !include Constructor to Define Jobs This example introduces the concept of !include constructor that can be used to organize more complex job manifiests. Specifically, we will see how we can include jobs in a manifest from any number of external YAML files. The manifests used in this example can be found in examples/1_job_manifests/sample_manifests/include_example . Here you will find 3 YAML files: advanced_manifest.yml julia_jobs.yml python_jobs.yml Let's take a look at each of these here: advance_manifest.yml --- version : 1.0 cluster_profile : my_slurm_cluster1 job_options : - matlab : &julia env_modules : - julia/1.7.2 cpus_per_task : 2 tasks : 1 memory_per_node : '2GB' - python : &python env_modules : - python/3.10.7 cpus_per_task : 2 tasks : 1 memory_per_node : '2GB' jobs : - !include julia_jobs.yml - !include python_jobs.yml This is the primary manifest that would be executed. The next two YAML files provide lists of job definitions. The first comprised entirely of MATLAB jobs while the second defines a list of Python jobs. This is one way in which the !include constructor can be used to organize a manifest better, and avoid having a single monstrous manifest for more complex workloads. julia_jobs.yml --- jobs : - julia_test1 : job_script : \"../../../scripts/test.jl\" standard_out : '~/julia_test1.out' standard_error : '~/julia_test1.err' job : *julia - julia_test2 : job_script : \"../../../scripts/test.jl\" standard_out : '~/julia_test2.out' standard_error : '~/julia_test2.err' job : *julia python_jobs.yml --- jobs : - python_test1 : job_script : \"../../../scripts/test.py\" standard_out : '~/python_test1.out' standard_error : '~/python_test1.err' job : *python - python_test2 : job_script : \"../../../scripts/test.py\" standard_out : '~/python_test2.out' standard_error : '~/python_test2.err' job : *python Notice that in both julia_jobs.yml and python_jobs.yml there are two SLURM configuration properties that are defined locally within the job definition block outside of the job section or not globally using the *python alias or *julia alias. This is useful when you'd like to have a series of jobs with similar resources requirements that can be defined through the use of aliases such as *python but also have some SLURM configuration options that you'd like to be different between each job definition. This is most apparent for standard_out and standard_error where having the same value accross jobs would result in the stdout and stderr files produced by one job being overwritten by the next. These are termed local job definitions, and they can be used for any SLURM configuration option found within the SlurmSubmit schema. The exceptions to this include: name : the job name is a required parameter that must be defined as the key or head of the node of the local job def (e.g: - python_test2: as shown in python_jobs.yaml ) env_modules : this parameter is not a SLURM configuration property but rather a \"wrapper\" for the environment property. It is setup, however, such that you are able to set this at the local or global level, since this may also be useful in some instance (e.g testing your code wih different versions of the language) Running the Example from the Cloned Repository See a Jupyter Notebook code sample for this example here if you're not interested in runnning it yourself \ud83d\udccd Move into examples directory and load anaconda3/2021.05 (or your favourite version, as long as python >= 3.6) $ cd slurmjobs/examples/1_job_manifests $ module load anaconda3/2021.05 \ud83d\udccd Execute the code // to view job object before submitting a job $ python3 1_include_example.py // to view job object before and after submitting a job $ python3 1_include_example.py -s","title":"Running the Example"},{"location":"examples/example2b/#example-2b-using-the-include-constructor-to-define-jobs","text":"This example introduces the concept of !include constructor that can be used to organize more complex job manifiests. Specifically, we will see how we can include jobs in a manifest from any number of external YAML files. The manifests used in this example can be found in examples/1_job_manifests/sample_manifests/include_example . Here you will find 3 YAML files: advanced_manifest.yml julia_jobs.yml python_jobs.yml Let's take a look at each of these here: advance_manifest.yml --- version : 1.0 cluster_profile : my_slurm_cluster1 job_options : - matlab : &julia env_modules : - julia/1.7.2 cpus_per_task : 2 tasks : 1 memory_per_node : '2GB' - python : &python env_modules : - python/3.10.7 cpus_per_task : 2 tasks : 1 memory_per_node : '2GB' jobs : - !include julia_jobs.yml - !include python_jobs.yml This is the primary manifest that would be executed. The next two YAML files provide lists of job definitions. The first comprised entirely of MATLAB jobs while the second defines a list of Python jobs. This is one way in which the !include constructor can be used to organize a manifest better, and avoid having a single monstrous manifest for more complex workloads. julia_jobs.yml --- jobs : - julia_test1 : job_script : \"../../../scripts/test.jl\" standard_out : '~/julia_test1.out' standard_error : '~/julia_test1.err' job : *julia - julia_test2 : job_script : \"../../../scripts/test.jl\" standard_out : '~/julia_test2.out' standard_error : '~/julia_test2.err' job : *julia python_jobs.yml --- jobs : - python_test1 : job_script : \"../../../scripts/test.py\" standard_out : '~/python_test1.out' standard_error : '~/python_test1.err' job : *python - python_test2 : job_script : \"../../../scripts/test.py\" standard_out : '~/python_test2.out' standard_error : '~/python_test2.err' job : *python Notice that in both julia_jobs.yml and python_jobs.yml there are two SLURM configuration properties that are defined locally within the job definition block outside of the job section or not globally using the *python alias or *julia alias. This is useful when you'd like to have a series of jobs with similar resources requirements that can be defined through the use of aliases such as *python but also have some SLURM configuration options that you'd like to be different between each job definition. This is most apparent for standard_out and standard_error where having the same value accross jobs would result in the stdout and stderr files produced by one job being overwritten by the next. These are termed local job definitions, and they can be used for any SLURM configuration option found within the SlurmSubmit schema. The exceptions to this include: name : the job name is a required parameter that must be defined as the key or head of the node of the local job def (e.g: - python_test2: as shown in python_jobs.yaml ) env_modules : this parameter is not a SLURM configuration property but rather a \"wrapper\" for the environment property. It is setup, however, such that you are able to set this at the local or global level, since this may also be useful in some instance (e.g testing your code wih different versions of the language)","title":"Example 2b - Using the !include Constructor to Define Jobs"},{"location":"examples/example2b/#running-the-example-from-the-cloned-repository","text":"See a Jupyter Notebook code sample for this example here if you're not interested in runnning it yourself \ud83d\udccd Move into examples directory and load anaconda3/2021.05 (or your favourite version, as long as python >= 3.6) $ cd slurmjobs/examples/1_job_manifests $ module load anaconda3/2021.05 \ud83d\udccd Execute the code // to view job object before submitting a job $ python3 1_include_example.py // to view job object before and after submitting a job $ python3 1_include_example.py -s","title":"Running the Example from the Cloned Repository"},{"location":"examples/example3/","text":"Example 3 - Best Practices for Complex Manifests The following example demonstrates the suggested setup when dealing with job manifests that span many YML files. This is discussed in greater detail here - a similar directory structure is used as describe. One addition is made, by including an 'output' directory in the manifest root directory. any number of sub-directories can be included and referenced within the main manifest root directory all relative paths defined within all YML files will be taken relative to the main manifest root directory The main manifest root in this example can be found in examples/2_job_manifests_bp/complextest/ . Here you will find 4 directories. jobs : contains YML files with job definitions that are referenced in the main manifest using the !include constructor opts : contains YML files with global job_options , also reference in the main manifest using the !include constructor scripts : contains scripts of various languages (particularly Python and R for this example) output : directory used to store stdout and stderr files from SLURM jobs The main job manifest is also found in this directory and is named complex-manifest.yaml after its purpose: testing various versions of R and Python with a new version of the optimization library KNITRO Let's take a look at each of these here: complex-manifest.yaml --- job_options : - complex_test : &job_opts cpus_per_task : 2 tasks : 1 memory_per_node : '2GB' The included global job_options are taken from the following: opts/job_opts.yaml --- job_options : - knitrotest : &knitrotest cpus_per_task : 2 tasks : 1 memory_per_node : '2GB' And the included jobs are taken from the following: jobs/python_jobs.yml --- jobs : - python_test1 : job_script : \"scripts/exampleConic1.py\" standard_out : 'output/complex-test/python3.10.7_test.out' standard_error : 'output/complex-test/python3.10.7_test.err' env_modules : - python/3.10.7 job : *job_opts - python_test2 : job_script : \"scripts/exampleConic1.py\" standard_out : 'output/complex-test/python3.8.14_test.out' standard_error : 'output/complex-test/python3.8.14.err' env_modules : - python3/3.8.14 job : *job_opts jobs/r_jobs.yml --- jobs : - r_test1 : job_script : \"scripts/rosenbrock.R\" standard_out : 'output/r/r421_test.out' standard_error : 'output/r/r421_test.err' env_modules : - R/4.2.1 job : *job_opts Running the Example from the Cloned Repository See a Jupyter Notebook code sample for this example here if you're not interested in runnning it yourself \ud83d\udccd Move into the example directory and load anaconda3/2021.05 (or your favourite version, as long as python >= 3.6) $ cd examples/2_job_manifests_bp/ $ module load anaconda3/2021.05 \ud83d\udccd Execute the code // to view job summaries before submitting a job $ python3 0_complex_manifest.py // to submit jobs $ python3 0_complex_manifest.py -s","title":"Running the Example"},{"location":"examples/example3/#example-3-best-practices-for-complex-manifests","text":"The following example demonstrates the suggested setup when dealing with job manifests that span many YML files. This is discussed in greater detail here - a similar directory structure is used as describe. One addition is made, by including an 'output' directory in the manifest root directory. any number of sub-directories can be included and referenced within the main manifest root directory all relative paths defined within all YML files will be taken relative to the main manifest root directory The main manifest root in this example can be found in examples/2_job_manifests_bp/complextest/ . Here you will find 4 directories. jobs : contains YML files with job definitions that are referenced in the main manifest using the !include constructor opts : contains YML files with global job_options , also reference in the main manifest using the !include constructor scripts : contains scripts of various languages (particularly Python and R for this example) output : directory used to store stdout and stderr files from SLURM jobs The main job manifest is also found in this directory and is named complex-manifest.yaml after its purpose: testing various versions of R and Python with a new version of the optimization library KNITRO Let's take a look at each of these here: complex-manifest.yaml --- job_options : - complex_test : &job_opts cpus_per_task : 2 tasks : 1 memory_per_node : '2GB' The included global job_options are taken from the following: opts/job_opts.yaml --- job_options : - knitrotest : &knitrotest cpus_per_task : 2 tasks : 1 memory_per_node : '2GB' And the included jobs are taken from the following: jobs/python_jobs.yml --- jobs : - python_test1 : job_script : \"scripts/exampleConic1.py\" standard_out : 'output/complex-test/python3.10.7_test.out' standard_error : 'output/complex-test/python3.10.7_test.err' env_modules : - python/3.10.7 job : *job_opts - python_test2 : job_script : \"scripts/exampleConic1.py\" standard_out : 'output/complex-test/python3.8.14_test.out' standard_error : 'output/complex-test/python3.8.14.err' env_modules : - python3/3.8.14 job : *job_opts jobs/r_jobs.yml --- jobs : - r_test1 : job_script : \"scripts/rosenbrock.R\" standard_out : 'output/r/r421_test.out' standard_error : 'output/r/r421_test.err' env_modules : - R/4.2.1 job : *job_opts","title":"Example 3 - Best Practices for Complex Manifests"},{"location":"examples/example3/#running-the-example-from-the-cloned-repository","text":"See a Jupyter Notebook code sample for this example here if you're not interested in runnning it yourself \ud83d\udccd Move into the example directory and load anaconda3/2021.05 (or your favourite version, as long as python >= 3.6) $ cd examples/2_job_manifests_bp/ $ module load anaconda3/2021.05 \ud83d\udccd Execute the code // to view job summaries before submitting a job $ python3 0_complex_manifest.py // to submit jobs $ python3 0_complex_manifest.py -s","title":"Running the Example from the Cloned Repository"},{"location":"extra/documentation/","text":"","title":"Writing Documentation for catena"},{"location":"extra/slurmapi/","text":"","title":"The SLURM REST API"},{"location":"jobs/slurmjob/","text":"SlurmJob The SlurmJob object is the most basic type of job in the catena library. The SlurmJob class provides a dynamic object for storing all information required to launch a job through the SLURM REST API programmatically, in Python. This type of SLURM Job is best suited for orchestrating work through the SLURM scheduler locally , meaning this class is best used in a script run on an HPC cluster with SLURM as the scheduler. This class is meant to be extended by other job types Attributes: Name Type Description job_options SlurmSubmit SlurmSubmit model containing all SLURM sbatch options name str SLURM job name, used to define the attribute of the same name in job_options user Optional [ str ] user-id of the user initializing this class. This will default to the user that has called this class (i.e you). env_modules Optional [ list ] list module names that should be loaded when submitting the job to a SLURM scheduler and made available to the environment running the job. For example, ['anaconda3/2021.11', 'matlab/96'] env_extra Optional [ Dict [ str , Any ]] dictionary of extra environment variables to export to the environment running the job submitted to a SLURM scheduler. For example, {'MYVAR': '/path/to/stuff'} . See how to append, prepend, or replace job_script Optional [ Union [ Callable [..., Any ], str ]] path to the script, either relative or absolute. The ~ is also excepted and converted to the appropriate absolute path for the current users directory. If using relative paths, be sure to understand where the paths should be relative to, to appropriately locate your scripts. job_script_args Optional [ List [ str ]] list of arguments to pass to the job_script when it is executed. For example, job_script_args=['--version'] command Optional [ str ] custom command to use when running job_script . If defined, the the script provided will be run as an executable with this command prepended. For example, command='python -m' would result in the job_script being called as: python -m <job_script> . Generally, the default should give the right result. jwt_lifespan amount of time in seconds for which the SLURM JWT token should be valid. The token is used to authenticate a given user when receiving requests, and expects that the user checking out the token exists within the SLURM user database. pyflake Optional [ bool ] if the defined job_script is a .py script, it will be flaked for un-used imports before stored internally. Source code in catena/jobs/slurm.py 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 class SlurmJob : \"\"\" The `SlurmJob` object is the most basic type of job in the `catena` library. The `SlurmJob` class provides a dynamic object for storing all information required to launch a job through the SLURM REST API programmatically, in Python. This type of SLURM `Job` is *best suited* for orchestrating work through the SLURM scheduler ***locally***, meaning this class is best used in a script run on an HPC cluster with SLURM as the scheduler. *This class is meant to be extended by other job types* Attributes: job_options: [SlurmSubmit](../schemas/slurm_job_schemas.md#slurm_submit) model containing all SLURM sbatch options name: SLURM job name, used to define the attribute of the same name in `job_options` user: user-id of the user initializing this class. This will default to the user that has called this class (i.e you). env_modules: list module names that should be loaded when submitting the job to a SLURM scheduler and made available to the environment running the job. For example, `['anaconda3/2021.11', 'matlab/96']` env_extra: dictionary of extra environment variables to export to the environment running the job submitted to a SLURM scheduler. For example, `{'MYVAR': '/path/to/stuff'}`. See how to [append, prepend, or replace](../examples/example1.md#env_extra_feats) job_script: path to the script, either relative or absolute. The `~` is also excepted and converted to the appropriate absolute path for the current users directory. ***If*** using relative paths, be sure to understand where the paths should be relative to, to appropriately locate your scripts. job_script_args: list of arguments to pass to the job_script when it is executed. For example, `job_script_args=['--version']` command: custom command to use when running `job_script`. If defined, the the script provided will be run as an executable with this command prepended. For example, command='python -m' would result in the `job_script` being called as: `python -m <job_script>`. Generally, the default should give the right result. jwt_lifespan: amount of time in seconds for which the SLURM JWT token should be valid. The token is used to authenticate a given user when receiving requests, and expects that the user checking out the token exists within the SLURM user database. pyflake: if the defined `job_script` is a .py script, it will be flaked for un-used imports before stored internally. \"\"\" job_options : SlurmSubmit = SlurmSubmit _token_info = {} _state = {} def __init__ ( self , name : str , profile : str , user : Optional [ str ] = pwd . getpwuid ( os . getuid ()) . pw_name , env_modules : Optional [ list ] = None , env_extra : Optional [ Dict [ str , Any ]] = None , job_script : Optional [ Union [ Callable [ ... , Any ], str ]] = None , job_script_args : Optional [ List [ str ]] = None , dependencies : Optional [ Dict [ DependencyType , Union [ str , List [ str ]]]] = None , command : Optional [ str ] = None , jwt_lifespan : Optional [ int ] = 7200 , pyflake : Optional [ bool ] = True , ** kwargs ): self . name : str = name self . profile : Union [ str , SlurmCluster ] = profile self . user : Optional [ str ] = user self . pyflake : Optional [ bool ] = pyflake self . job_script : Optional [ Union [ Callable [ ... , Any ], str ]] = job_script self . command : Optional [ str ] = command self . dependencies = dependencies self . depmap = defaultdict ( list ) # if context not set, set context root to callable path if not env . CONTEXT_ROOT : cpath = Path ( sys . argv [ 0 ]) if ( cpath . is_file () and 'site-packages' not in sys . argv [ 0 ] . split ( os . path . sep )): env . CONTEXT_ROOT = Path ( cpath . resolve ()) . parent if isinstance ( self . job_script , str ): self . job_script = str ( Path ( env . CONTEXT_ROOT ) / self . job_script ) # check if path exists and read in - in remote job overload this # attribute and check if path is remote or local if isinstance ( self . job_script , str ): self . job_script_args : Optional [ List [ str ]] = job_script_args with JobScript ( self . job_script , job_script_args = self . job_script_args , command = command ) as code : self . script = code . script self . code = code #self.__context_tree = ContextTree # TODO: allow being passed a function # else: # with PyFunction(job_script) as code: # self.script = code.script self . __lifespan : Optional [ int ] = jwt_lifespan self . token = self . generate_token () # build request url self . api_version = self . profile . api_version self . protocol = self . profile . api_proto self . host = self . profile . api_host self . port = self . profile . api_port self . url = f \" { self . protocol } :// { self . host } : { self . port } /slurm/v { self . api_version } /job/submit\" # unload any loaded versions of python that could conflict module ( 'unload' , * [ 'python' , 'python3' , 'anaconda' , 'anaconda3' ]) # load requested modules to environment self . env_modules : Optional [ list ] = env_modules if env_modules is not None : module ( 'load' , * self . env_modules ) self . env_extra : Optional [ Dict [ str , Any ]] = env_extra self . __set_environment ( ** kwargs ) # build request self . slurm_header = self . request_header () self . request = SlurmModel ( job = self . job_options ( environment = self . environment , name = self . name , dependency = self . depstr , ** kwargs ), script = self . script ) self . jobid = None self . monitor_polls = 0 self . job_monitor = {} def __enter__ ( self ): return self def __exit__ ( self , exc_type , exc_val , exc_tb ): pass def __str__ ( self ): job_sum = self . request . job . dict () job_sum = { k : v for k , v in job_sum . items () if 'environment' not in k } job_sum = { k : v for k , v in job_sum . items () if 'name' not in k } job_string = '' for key , val in job_sum . items (): job_string += f ' \\t\\t { key } : { val } \\n ' formatted_script = ' \\n ' . join ([ ' \\t\\t {} ' . format ( x ) for x in self . script . split ( \" \\n \" )]) # should add if statement to add additional attributes that appear after submitting or begining to monitor import textwrap return textwrap . dedent ( f \"\"\" \ud83e\udd16 User: { self . user } \ud83d\udcc7 Job Name: { self . name } \ud83d\udcdc Job Script Language: { self . code . lang } \ud83c\udf9f\ufe0f JWT Token: { self . token } \ud83d\udda5\ufe0f API Host: { self . host } \ud83c\udf10 URL: { self . url } \ud83d\udc0d Pyflake: { self . pyflake } \ud83d\udd79\ufe0f Modules: { self . env_modules } \ud83c\udf9b\ufe0f Extra Env: { self . env_extra } \ud83d\udce1 Request Summary: \ud83d\udee0\ufe0f job: { job_string } \ud83d\udcdc script: { formatted_script } \"\"\" ) def __repr__ ( self ): return f \" { self . name } { self . jobid } \" def context_tree ( self ): ctx_tree = ContextTree . render () def __set_environment ( self , ** kwargs ): # parse current environment local_env = dict ( os . environ ) # add user defined env vars to local environmnet if self . env_extra is not None : # create local copy of extra_env udef = self . env_extra . copy () for key in self . env_extra . keys (): # set to user defined value when not defined in local env if local_env . get ( key ) is None : local_env [ key ] = udef . pop ( key ) # prepend user defined value to local env when defined locally else : uval = udef . pop ( key ) # if var def starts with : then append to local env value if uval . startswith ( \":\" ): local_env [ key ] = f \" { local_env [ key ] }{ uval } \" # if var def ends with : then prepend to local env value elif uval . endswith ( \":\" ): local_env [ key ] = f \" { uval }{ local_env [ key ] } \" # else overwrite the local env value else : local_env [ key ] = uval # remove json type variables that don't do well with requests local_env = { k : v for k , v in local_env . items () if 'BASH_FUNC' not in k } self . environment = local_env @property def profile ( self ): return self . __profile @profile . setter def profile ( self , prof : str ): \"\"\" The default catena configuration file is expected in ~/.catena/conf.yml. When the profile name alone is provided, catena will automatically look at this path to find the profile. To define a profile defined at a non- default path, one should specify prof = profile_name@/path/to/config/file.yml \"\"\" if '@' in prof : conf = CatenaConfig . read ( prof . split ( '@' )[ - 1 ]) self . __profile = conf . get_profile ( prof . split ( '@' )[ 0 ]) else : conf = CatenaConfig . read () self . __profile = conf . get_profile ( prof ) return self . __profile @property def jwt_lifespan ( self ): \"\"\" Ensures that shared token accross multiple jobs will have the same value for jwt_ifespan as that of the first job submitted (i.e the token should expire at the same time) \"\"\" if self . _token_info . get ( 'jwt_lifespan' ) is not None : return self . _token_info . get ( 'jwt_lifespan' ) else : self . _token_info . setdefault ( 'jwt_lifespan' , self . __lifespan ) return self . __lifespan @property def jwt_token_expired ( self ): if self . _token_info . get ( 'jwt_start_time' ) is not None : return time . time () - self . _token_info . get ( 'jwt_start_time' ) >= self . jwt_lifespan else : return False @property def jwt_start_time ( self ): return self . _token_info . get ( 'jwt_start_time' ) @property def jwt_elapsed_time ( self ): if self . _token_info . get ( 'jwt_start_time' ) is None : return None else : return time . time () - self . jwt_start_time @property def depstr ( self ): depstr = '' for deptype , deps in self . depmap . items (): tmp = '' for dep in deps : tmp += f \" { dep . jobid } :\" depstr += f \" { deptype } : { tmp . strip ( ':' ) } ,\" return depstr . strip ( ',' ) def submit ( self , job_monitor : Optional [ bool ] = False , delay : Optional [ int ] = 0 ): \"\"\" Submit a simple local script Need to check for shebangs #! in script (needed) Need to load the right environment modules to run the script remote submit should have options to copy local data to remote cluster in working directory for job \"\"\" response = requests . post ( self . url , data = json . dumps ( self . request . dict ( exclude_unset = True )), headers = self . slurm_header ) self . response = json . loads ( response . content ) self . jobid = self . response [ 'job_id' ] if delay > 0 : time . sleep ( delay ) def monitor ( self , poll_time = 5 ): self . monitor_url = f \" { self . protocol } :// { self . host } : { self . port } /slurm/v { self . api_version } /job/ { self . jobid } \" response = requests . get ( self . monitor_url , headers = self . request_header ()) self . jwt_elapsed_time = time . time () - self . jwt_start_time try : self . job_state = response [ 'job_state' ] self . _state [ self . name ] = { 'jobid' : self . jobid , 'state' : self . job_state } if self . job_state == \"QUEUED\" : logger . info ( f \"Job { self . jobid } is currently: { self . job_state } \" ) time . sleep ( poll_time * 2 ) self . monitor () if self . job_state == \"RUNNING\" : logger . info ( f \"Job { self . jobid } is currently: { self . job_state } \" ) time . sleep ( poll_time ) self . monitor () if ( self . job_state == \"COMPLETED\" or self . job_state == \"CANCELLED\" ): logger . info ( f \"Job { self . jobid } has changed state to: { self . job_state } \" ) return self . job_state , self . monitor_polls if ( self . job_state == \"TIMEOUT\" or self . job_state == \"FAILED\" ): logger . error ( f \"Job { self . jobid } has changed state to: { self . job_state } \" ) return self . job_state , self . monitor_polls except KeyError : logger . error ( \"Job state not found\" ) # generate new jwt token if expired if self . jwt_token_expired : logger . error ( f \"JWT token has expired ( { self . jwt_elapsed_time } >= { self . jwt_lifespan } )\" ) logger . info ( \"Generating a new token\" ) else : logger . error ( \"Somethings not right here ... check if job {self.jobid} exists in SLURM DB\" ) exit ( 1 ) def generate_token ( self , encoding = 'utf-8' ): \"\"\" Generate SLURM JWT token for authenticating request \"\"\" if self . _token_info . get ( 'jwt_token' ) is None : # generate jwt token process = subprocess . Popen ([ 'scontrol' , 'token' , f 'lifespan= { self . __lifespan } ' ], stdout = PIPE , stderr = PIPE ) raw , err = process . communicate () # start token expiry timer self . _token_info . setdefault ( 'jwt_start_time' , time . time ()) # set job token attribute jwt_token = raw . decode ( encoding ) . rstrip () . split ( '=' )[ - 1 ] logger . info ( f \"SLURM_JWT= { jwt_token } \" ) self . _token_info . setdefault ( 'jwt_token' , jwt_token ) if self . jwt_token_expired : self . _token_info = {} self . generate_token ( encoding = encoding ) return self . _token_info . get ( 'jwt_token' ) def request_header ( self ): \"\"\" Generate request header with username and JWT token \"\"\" return { 'Content-Type' : 'application/json' , 'X-SLURM-USER-NAME' : self . user , 'X-SLURM-USER-TOKEN' : self . token } jwt_lifespan property Ensures that shared token accross multiple jobs will have the same value for jwt_ifespan as that of the first job submitted (i.e the token should expire at the same time) generate_token ( encoding = 'utf-8' ) Generate SLURM JWT token for authenticating request Source code in catena/jobs/slurm.py 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 def generate_token ( self , encoding = 'utf-8' ): \"\"\" Generate SLURM JWT token for authenticating request \"\"\" if self . _token_info . get ( 'jwt_token' ) is None : # generate jwt token process = subprocess . Popen ([ 'scontrol' , 'token' , f 'lifespan= { self . __lifespan } ' ], stdout = PIPE , stderr = PIPE ) raw , err = process . communicate () # start token expiry timer self . _token_info . setdefault ( 'jwt_start_time' , time . time ()) # set job token attribute jwt_token = raw . decode ( encoding ) . rstrip () . split ( '=' )[ - 1 ] logger . info ( f \"SLURM_JWT= { jwt_token } \" ) self . _token_info . setdefault ( 'jwt_token' , jwt_token ) if self . jwt_token_expired : self . _token_info = {} self . generate_token ( encoding = encoding ) return self . _token_info . get ( 'jwt_token' ) request_header () Generate request header with username and JWT token Source code in catena/jobs/slurm.py 408 409 410 411 412 413 414 415 416 def request_header ( self ): \"\"\" Generate request header with username and JWT token \"\"\" return { 'Content-Type' : 'application/json' , 'X-SLURM-USER-NAME' : self . user , 'X-SLURM-USER-TOKEN' : self . token } submit ( job_monitor = False , delay = 0 ) Submit a simple local script Need to check for shebangs #! in script (needed) Need to load the right environment modules to run the script remote submit should have options to copy local data to remote cluster in working directory for job Source code in catena/jobs/slurm.py 325 326 327 328 329 330 331 332 333 334 335 336 337 338 def submit ( self , job_monitor : Optional [ bool ] = False , delay : Optional [ int ] = 0 ): \"\"\" Submit a simple local script Need to check for shebangs #! in script (needed) Need to load the right environment modules to run the script remote submit should have options to copy local data to remote cluster in working directory for job \"\"\" response = requests . post ( self . url , data = json . dumps ( self . request . dict ( exclude_unset = True )), headers = self . slurm_header ) self . response = json . loads ( response . content ) self . jobid = self . response [ 'job_id' ] if delay > 0 : time . sleep ( delay ) New Attributes After Submitting a SlurmJob self.response (dict) raw response from SLURM REST API after invoking POST job/submit ; self.jobid (str) SLURM job id for the instance of SLURMRESTJob ; New Attributes After Starting Monitoring of a SLURMRESTJob self.monitor_url (str) dynamically constructed API URL based on api_version, protocol, host, port attributes for GET job/{job_id} ; self.jwt_elapsed_time (float) amount of time in seconds that have elapsed since JWT token was checked out - triggers generate_token when JWT token is expired;\\ self.job_state (str) the jobs current state - this attribute is updated everytime the job state is polled (cf. SLURM Job States ) ; Extra Options Extra options are options that are not SLURM sbatch options, but are required for defining a Job instance. These include: env_modules job_script env_extra job_script_args command \ud83d\udcdd Note : The definition of each of these can be found above \ud83d\udcdd Note : How to append, prepend and replace","title":"<a name=\"slurmrestjob\"></a>`SlurmJob`"},{"location":"jobs/slurmjob/#slurmjob","text":"The SlurmJob object is the most basic type of job in the catena library. The SlurmJob class provides a dynamic object for storing all information required to launch a job through the SLURM REST API programmatically, in Python. This type of SLURM Job is best suited for orchestrating work through the SLURM scheduler locally , meaning this class is best used in a script run on an HPC cluster with SLURM as the scheduler. This class is meant to be extended by other job types Attributes: Name Type Description job_options SlurmSubmit SlurmSubmit model containing all SLURM sbatch options name str SLURM job name, used to define the attribute of the same name in job_options user Optional [ str ] user-id of the user initializing this class. This will default to the user that has called this class (i.e you). env_modules Optional [ list ] list module names that should be loaded when submitting the job to a SLURM scheduler and made available to the environment running the job. For example, ['anaconda3/2021.11', 'matlab/96'] env_extra Optional [ Dict [ str , Any ]] dictionary of extra environment variables to export to the environment running the job submitted to a SLURM scheduler. For example, {'MYVAR': '/path/to/stuff'} . See how to append, prepend, or replace job_script Optional [ Union [ Callable [..., Any ], str ]] path to the script, either relative or absolute. The ~ is also excepted and converted to the appropriate absolute path for the current users directory. If using relative paths, be sure to understand where the paths should be relative to, to appropriately locate your scripts. job_script_args Optional [ List [ str ]] list of arguments to pass to the job_script when it is executed. For example, job_script_args=['--version'] command Optional [ str ] custom command to use when running job_script . If defined, the the script provided will be run as an executable with this command prepended. For example, command='python -m' would result in the job_script being called as: python -m <job_script> . Generally, the default should give the right result. jwt_lifespan amount of time in seconds for which the SLURM JWT token should be valid. The token is used to authenticate a given user when receiving requests, and expects that the user checking out the token exists within the SLURM user database. pyflake Optional [ bool ] if the defined job_script is a .py script, it will be flaked for un-used imports before stored internally. Source code in catena/jobs/slurm.py 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 class SlurmJob : \"\"\" The `SlurmJob` object is the most basic type of job in the `catena` library. The `SlurmJob` class provides a dynamic object for storing all information required to launch a job through the SLURM REST API programmatically, in Python. This type of SLURM `Job` is *best suited* for orchestrating work through the SLURM scheduler ***locally***, meaning this class is best used in a script run on an HPC cluster with SLURM as the scheduler. *This class is meant to be extended by other job types* Attributes: job_options: [SlurmSubmit](../schemas/slurm_job_schemas.md#slurm_submit) model containing all SLURM sbatch options name: SLURM job name, used to define the attribute of the same name in `job_options` user: user-id of the user initializing this class. This will default to the user that has called this class (i.e you). env_modules: list module names that should be loaded when submitting the job to a SLURM scheduler and made available to the environment running the job. For example, `['anaconda3/2021.11', 'matlab/96']` env_extra: dictionary of extra environment variables to export to the environment running the job submitted to a SLURM scheduler. For example, `{'MYVAR': '/path/to/stuff'}`. See how to [append, prepend, or replace](../examples/example1.md#env_extra_feats) job_script: path to the script, either relative or absolute. The `~` is also excepted and converted to the appropriate absolute path for the current users directory. ***If*** using relative paths, be sure to understand where the paths should be relative to, to appropriately locate your scripts. job_script_args: list of arguments to pass to the job_script when it is executed. For example, `job_script_args=['--version']` command: custom command to use when running `job_script`. If defined, the the script provided will be run as an executable with this command prepended. For example, command='python -m' would result in the `job_script` being called as: `python -m <job_script>`. Generally, the default should give the right result. jwt_lifespan: amount of time in seconds for which the SLURM JWT token should be valid. The token is used to authenticate a given user when receiving requests, and expects that the user checking out the token exists within the SLURM user database. pyflake: if the defined `job_script` is a .py script, it will be flaked for un-used imports before stored internally. \"\"\" job_options : SlurmSubmit = SlurmSubmit _token_info = {} _state = {} def __init__ ( self , name : str , profile : str , user : Optional [ str ] = pwd . getpwuid ( os . getuid ()) . pw_name , env_modules : Optional [ list ] = None , env_extra : Optional [ Dict [ str , Any ]] = None , job_script : Optional [ Union [ Callable [ ... , Any ], str ]] = None , job_script_args : Optional [ List [ str ]] = None , dependencies : Optional [ Dict [ DependencyType , Union [ str , List [ str ]]]] = None , command : Optional [ str ] = None , jwt_lifespan : Optional [ int ] = 7200 , pyflake : Optional [ bool ] = True , ** kwargs ): self . name : str = name self . profile : Union [ str , SlurmCluster ] = profile self . user : Optional [ str ] = user self . pyflake : Optional [ bool ] = pyflake self . job_script : Optional [ Union [ Callable [ ... , Any ], str ]] = job_script self . command : Optional [ str ] = command self . dependencies = dependencies self . depmap = defaultdict ( list ) # if context not set, set context root to callable path if not env . CONTEXT_ROOT : cpath = Path ( sys . argv [ 0 ]) if ( cpath . is_file () and 'site-packages' not in sys . argv [ 0 ] . split ( os . path . sep )): env . CONTEXT_ROOT = Path ( cpath . resolve ()) . parent if isinstance ( self . job_script , str ): self . job_script = str ( Path ( env . CONTEXT_ROOT ) / self . job_script ) # check if path exists and read in - in remote job overload this # attribute and check if path is remote or local if isinstance ( self . job_script , str ): self . job_script_args : Optional [ List [ str ]] = job_script_args with JobScript ( self . job_script , job_script_args = self . job_script_args , command = command ) as code : self . script = code . script self . code = code #self.__context_tree = ContextTree # TODO: allow being passed a function # else: # with PyFunction(job_script) as code: # self.script = code.script self . __lifespan : Optional [ int ] = jwt_lifespan self . token = self . generate_token () # build request url self . api_version = self . profile . api_version self . protocol = self . profile . api_proto self . host = self . profile . api_host self . port = self . profile . api_port self . url = f \" { self . protocol } :// { self . host } : { self . port } /slurm/v { self . api_version } /job/submit\" # unload any loaded versions of python that could conflict module ( 'unload' , * [ 'python' , 'python3' , 'anaconda' , 'anaconda3' ]) # load requested modules to environment self . env_modules : Optional [ list ] = env_modules if env_modules is not None : module ( 'load' , * self . env_modules ) self . env_extra : Optional [ Dict [ str , Any ]] = env_extra self . __set_environment ( ** kwargs ) # build request self . slurm_header = self . request_header () self . request = SlurmModel ( job = self . job_options ( environment = self . environment , name = self . name , dependency = self . depstr , ** kwargs ), script = self . script ) self . jobid = None self . monitor_polls = 0 self . job_monitor = {} def __enter__ ( self ): return self def __exit__ ( self , exc_type , exc_val , exc_tb ): pass def __str__ ( self ): job_sum = self . request . job . dict () job_sum = { k : v for k , v in job_sum . items () if 'environment' not in k } job_sum = { k : v for k , v in job_sum . items () if 'name' not in k } job_string = '' for key , val in job_sum . items (): job_string += f ' \\t\\t { key } : { val } \\n ' formatted_script = ' \\n ' . join ([ ' \\t\\t {} ' . format ( x ) for x in self . script . split ( \" \\n \" )]) # should add if statement to add additional attributes that appear after submitting or begining to monitor import textwrap return textwrap . dedent ( f \"\"\" \ud83e\udd16 User: { self . user } \ud83d\udcc7 Job Name: { self . name } \ud83d\udcdc Job Script Language: { self . code . lang } \ud83c\udf9f\ufe0f JWT Token: { self . token } \ud83d\udda5\ufe0f API Host: { self . host } \ud83c\udf10 URL: { self . url } \ud83d\udc0d Pyflake: { self . pyflake } \ud83d\udd79\ufe0f Modules: { self . env_modules } \ud83c\udf9b\ufe0f Extra Env: { self . env_extra } \ud83d\udce1 Request Summary: \ud83d\udee0\ufe0f job: { job_string } \ud83d\udcdc script: { formatted_script } \"\"\" ) def __repr__ ( self ): return f \" { self . name } { self . jobid } \" def context_tree ( self ): ctx_tree = ContextTree . render () def __set_environment ( self , ** kwargs ): # parse current environment local_env = dict ( os . environ ) # add user defined env vars to local environmnet if self . env_extra is not None : # create local copy of extra_env udef = self . env_extra . copy () for key in self . env_extra . keys (): # set to user defined value when not defined in local env if local_env . get ( key ) is None : local_env [ key ] = udef . pop ( key ) # prepend user defined value to local env when defined locally else : uval = udef . pop ( key ) # if var def starts with : then append to local env value if uval . startswith ( \":\" ): local_env [ key ] = f \" { local_env [ key ] }{ uval } \" # if var def ends with : then prepend to local env value elif uval . endswith ( \":\" ): local_env [ key ] = f \" { uval }{ local_env [ key ] } \" # else overwrite the local env value else : local_env [ key ] = uval # remove json type variables that don't do well with requests local_env = { k : v for k , v in local_env . items () if 'BASH_FUNC' not in k } self . environment = local_env @property def profile ( self ): return self . __profile @profile . setter def profile ( self , prof : str ): \"\"\" The default catena configuration file is expected in ~/.catena/conf.yml. When the profile name alone is provided, catena will automatically look at this path to find the profile. To define a profile defined at a non- default path, one should specify prof = profile_name@/path/to/config/file.yml \"\"\" if '@' in prof : conf = CatenaConfig . read ( prof . split ( '@' )[ - 1 ]) self . __profile = conf . get_profile ( prof . split ( '@' )[ 0 ]) else : conf = CatenaConfig . read () self . __profile = conf . get_profile ( prof ) return self . __profile @property def jwt_lifespan ( self ): \"\"\" Ensures that shared token accross multiple jobs will have the same value for jwt_ifespan as that of the first job submitted (i.e the token should expire at the same time) \"\"\" if self . _token_info . get ( 'jwt_lifespan' ) is not None : return self . _token_info . get ( 'jwt_lifespan' ) else : self . _token_info . setdefault ( 'jwt_lifespan' , self . __lifespan ) return self . __lifespan @property def jwt_token_expired ( self ): if self . _token_info . get ( 'jwt_start_time' ) is not None : return time . time () - self . _token_info . get ( 'jwt_start_time' ) >= self . jwt_lifespan else : return False @property def jwt_start_time ( self ): return self . _token_info . get ( 'jwt_start_time' ) @property def jwt_elapsed_time ( self ): if self . _token_info . get ( 'jwt_start_time' ) is None : return None else : return time . time () - self . jwt_start_time @property def depstr ( self ): depstr = '' for deptype , deps in self . depmap . items (): tmp = '' for dep in deps : tmp += f \" { dep . jobid } :\" depstr += f \" { deptype } : { tmp . strip ( ':' ) } ,\" return depstr . strip ( ',' ) def submit ( self , job_monitor : Optional [ bool ] = False , delay : Optional [ int ] = 0 ): \"\"\" Submit a simple local script Need to check for shebangs #! in script (needed) Need to load the right environment modules to run the script remote submit should have options to copy local data to remote cluster in working directory for job \"\"\" response = requests . post ( self . url , data = json . dumps ( self . request . dict ( exclude_unset = True )), headers = self . slurm_header ) self . response = json . loads ( response . content ) self . jobid = self . response [ 'job_id' ] if delay > 0 : time . sleep ( delay ) def monitor ( self , poll_time = 5 ): self . monitor_url = f \" { self . protocol } :// { self . host } : { self . port } /slurm/v { self . api_version } /job/ { self . jobid } \" response = requests . get ( self . monitor_url , headers = self . request_header ()) self . jwt_elapsed_time = time . time () - self . jwt_start_time try : self . job_state = response [ 'job_state' ] self . _state [ self . name ] = { 'jobid' : self . jobid , 'state' : self . job_state } if self . job_state == \"QUEUED\" : logger . info ( f \"Job { self . jobid } is currently: { self . job_state } \" ) time . sleep ( poll_time * 2 ) self . monitor () if self . job_state == \"RUNNING\" : logger . info ( f \"Job { self . jobid } is currently: { self . job_state } \" ) time . sleep ( poll_time ) self . monitor () if ( self . job_state == \"COMPLETED\" or self . job_state == \"CANCELLED\" ): logger . info ( f \"Job { self . jobid } has changed state to: { self . job_state } \" ) return self . job_state , self . monitor_polls if ( self . job_state == \"TIMEOUT\" or self . job_state == \"FAILED\" ): logger . error ( f \"Job { self . jobid } has changed state to: { self . job_state } \" ) return self . job_state , self . monitor_polls except KeyError : logger . error ( \"Job state not found\" ) # generate new jwt token if expired if self . jwt_token_expired : logger . error ( f \"JWT token has expired ( { self . jwt_elapsed_time } >= { self . jwt_lifespan } )\" ) logger . info ( \"Generating a new token\" ) else : logger . error ( \"Somethings not right here ... check if job {self.jobid} exists in SLURM DB\" ) exit ( 1 ) def generate_token ( self , encoding = 'utf-8' ): \"\"\" Generate SLURM JWT token for authenticating request \"\"\" if self . _token_info . get ( 'jwt_token' ) is None : # generate jwt token process = subprocess . Popen ([ 'scontrol' , 'token' , f 'lifespan= { self . __lifespan } ' ], stdout = PIPE , stderr = PIPE ) raw , err = process . communicate () # start token expiry timer self . _token_info . setdefault ( 'jwt_start_time' , time . time ()) # set job token attribute jwt_token = raw . decode ( encoding ) . rstrip () . split ( '=' )[ - 1 ] logger . info ( f \"SLURM_JWT= { jwt_token } \" ) self . _token_info . setdefault ( 'jwt_token' , jwt_token ) if self . jwt_token_expired : self . _token_info = {} self . generate_token ( encoding = encoding ) return self . _token_info . get ( 'jwt_token' ) def request_header ( self ): \"\"\" Generate request header with username and JWT token \"\"\" return { 'Content-Type' : 'application/json' , 'X-SLURM-USER-NAME' : self . user , 'X-SLURM-USER-TOKEN' : self . token }","title":"SlurmJob"},{"location":"jobs/slurmjob/#catena.jobs.slurm.SlurmJob.jwt_lifespan","text":"Ensures that shared token accross multiple jobs will have the same value for jwt_ifespan as that of the first job submitted (i.e the token should expire at the same time)","title":"jwt_lifespan"},{"location":"jobs/slurmjob/#catena.jobs.slurm.SlurmJob.generate_token","text":"Generate SLURM JWT token for authenticating request Source code in catena/jobs/slurm.py 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 def generate_token ( self , encoding = 'utf-8' ): \"\"\" Generate SLURM JWT token for authenticating request \"\"\" if self . _token_info . get ( 'jwt_token' ) is None : # generate jwt token process = subprocess . Popen ([ 'scontrol' , 'token' , f 'lifespan= { self . __lifespan } ' ], stdout = PIPE , stderr = PIPE ) raw , err = process . communicate () # start token expiry timer self . _token_info . setdefault ( 'jwt_start_time' , time . time ()) # set job token attribute jwt_token = raw . decode ( encoding ) . rstrip () . split ( '=' )[ - 1 ] logger . info ( f \"SLURM_JWT= { jwt_token } \" ) self . _token_info . setdefault ( 'jwt_token' , jwt_token ) if self . jwt_token_expired : self . _token_info = {} self . generate_token ( encoding = encoding ) return self . _token_info . get ( 'jwt_token' )","title":"generate_token()"},{"location":"jobs/slurmjob/#catena.jobs.slurm.SlurmJob.request_header","text":"Generate request header with username and JWT token Source code in catena/jobs/slurm.py 408 409 410 411 412 413 414 415 416 def request_header ( self ): \"\"\" Generate request header with username and JWT token \"\"\" return { 'Content-Type' : 'application/json' , 'X-SLURM-USER-NAME' : self . user , 'X-SLURM-USER-TOKEN' : self . token }","title":"request_header()"},{"location":"jobs/slurmjob/#catena.jobs.slurm.SlurmJob.submit","text":"Submit a simple local script Need to check for shebangs #! in script (needed) Need to load the right environment modules to run the script remote submit should have options to copy local data to remote cluster in working directory for job Source code in catena/jobs/slurm.py 325 326 327 328 329 330 331 332 333 334 335 336 337 338 def submit ( self , job_monitor : Optional [ bool ] = False , delay : Optional [ int ] = 0 ): \"\"\" Submit a simple local script Need to check for shebangs #! in script (needed) Need to load the right environment modules to run the script remote submit should have options to copy local data to remote cluster in working directory for job \"\"\" response = requests . post ( self . url , data = json . dumps ( self . request . dict ( exclude_unset = True )), headers = self . slurm_header ) self . response = json . loads ( response . content ) self . jobid = self . response [ 'job_id' ] if delay > 0 : time . sleep ( delay )","title":"submit()"},{"location":"jobs/slurmjob/#new-attributes-after-submitting-a-slurmjob","text":"self.response (dict) raw response from SLURM REST API after invoking POST job/submit ; self.jobid (str) SLURM job id for the instance of SLURMRESTJob ;","title":"New Attributes After Submitting a SlurmJob"},{"location":"jobs/slurmjob/#new-attributes-after-starting-monitoring-of-a-slurmrestjob","text":"self.monitor_url (str) dynamically constructed API URL based on api_version, protocol, host, port attributes for GET job/{job_id} ; self.jwt_elapsed_time (float) amount of time in seconds that have elapsed since JWT token was checked out - triggers generate_token when JWT token is expired;\\ self.job_state (str) the jobs current state - this attribute is updated everytime the job state is polled (cf. SLURM Job States ) ;","title":"New Attributes After Starting Monitoring of a SLURMRESTJob"},{"location":"jobs/slurmjob/#extra-options","text":"Extra options are options that are not SLURM sbatch options, but are required for defining a Job instance. These include: env_modules job_script env_extra job_script_args command \ud83d\udcdd Note : The definition of each of these can be found above \ud83d\udcdd Note : How to append, prepend and replace","title":"Extra Options"},{"location":"models/config/","text":"Catena Config Model Bases: ExtendedBaseModel Source code in catena/models/config.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 class CatenaConfig ( ExtendedBaseModel ): version : Optional [ str ] = 1.0 clusters : Optional [ Dict [ str , ClusterDefinition ]] = {} @classmethod def read ( cls , path : Optional [ str ] = None ): \"\"\" Read configuration from specified yaml file \"\"\" if path is None : path = Path . home () / \".catena/conf.yml\" if not Path ( path ) . is_file (): print ( f \"\u26a0\ufe0f [red] file does not exist: { path } [/red]\" ) exit ( 1 ) # read manifest with open ( path , 'r' ) as f : data = safe_loader ( f , Loader = Loader ) return cls ( ** data ) def cluster_profiles ( self ): \"\"\" Returns available cluster profiles defined in catena configuration file \"\"\" return list ( self . clusters . keys ()) def get_profile ( self , name : str ): \"\"\" Return configuration properties for the named cluster profile \"\"\" if name in self . clusters : return self . clusters . get ( name ) print ( f \"\u26a0\ufe0f [red] profile ' { name } ' does not exist[/red]\" ) print ( f \"Possiblities include: { self . cluster_profiles () } \" ) cluster_profiles () Returns available cluster profiles defined in catena configuration file Source code in catena/models/config.py 75 76 77 78 79 80 def cluster_profiles ( self ): \"\"\" Returns available cluster profiles defined in catena configuration file \"\"\" return list ( self . clusters . keys ()) get_profile ( name ) Return configuration properties for the named cluster profile Source code in catena/models/config.py 83 84 85 86 87 88 89 90 91 def get_profile ( self , name : str ): \"\"\" Return configuration properties for the named cluster profile \"\"\" if name in self . clusters : return self . clusters . get ( name ) print ( f \"\u26a0\ufe0f [red] profile ' { name } ' does not exist[/red]\" ) print ( f \"Possiblities include: { self . cluster_profiles () } \" ) read ( path = None ) classmethod Read configuration from specified yaml file Source code in catena/models/config.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 @classmethod def read ( cls , path : Optional [ str ] = None ): \"\"\" Read configuration from specified yaml file \"\"\" if path is None : path = Path . home () / \".catena/conf.yml\" if not Path ( path ) . is_file (): print ( f \"\u26a0\ufe0f [red] file does not exist: { path } [/red]\" ) exit ( 1 ) # read manifest with open ( path , 'r' ) as f : data = safe_loader ( f , Loader = Loader ) return cls ( ** data ) Cluster Definition Model Bases: BaseModel Source code in catena/models/config.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 class ClusterDefinition ( BaseModel ): backend : Optional [ str ] = 'slurm' class Config : extra = Extra . allow arbitrary_types_allowed = True def __init__ ( self , ** kwargs ): super () . __init__ ( ** kwargs ) cluster_args = { k : v for k , v in kwargs . items () if k not in self . __fields__ } if self . backend == 'slurm' : slurm_cluster = SlurmCluster ( ** cluster_args ) for attr , val in slurm_cluster . dict () . items (): self . __dict__ [ attr ] = val self . _cluster = slurm_cluster SLURM Cluster Definition Model Bases: BaseModel Source code in catena/models/config.py 12 13 14 15 16 17 18 19 class SlurmCluster ( BaseModel ): api_host : str api_proto : Optional [ str ] = 'http' api_version : Optional [ str ] = '0.0.35' api_port : Optional [ str ] = '6820' class Config : api_version_compat = [ '0.0.35' ]","title":"Catena Config"},{"location":"models/config/#catena-config-model","text":"Bases: ExtendedBaseModel Source code in catena/models/config.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 class CatenaConfig ( ExtendedBaseModel ): version : Optional [ str ] = 1.0 clusters : Optional [ Dict [ str , ClusterDefinition ]] = {} @classmethod def read ( cls , path : Optional [ str ] = None ): \"\"\" Read configuration from specified yaml file \"\"\" if path is None : path = Path . home () / \".catena/conf.yml\" if not Path ( path ) . is_file (): print ( f \"\u26a0\ufe0f [red] file does not exist: { path } [/red]\" ) exit ( 1 ) # read manifest with open ( path , 'r' ) as f : data = safe_loader ( f , Loader = Loader ) return cls ( ** data ) def cluster_profiles ( self ): \"\"\" Returns available cluster profiles defined in catena configuration file \"\"\" return list ( self . clusters . keys ()) def get_profile ( self , name : str ): \"\"\" Return configuration properties for the named cluster profile \"\"\" if name in self . clusters : return self . clusters . get ( name ) print ( f \"\u26a0\ufe0f [red] profile ' { name } ' does not exist[/red]\" ) print ( f \"Possiblities include: { self . cluster_profiles () } \" )","title":"Catena Config Model"},{"location":"models/config/#catena.models.config.CatenaConfig.cluster_profiles","text":"Returns available cluster profiles defined in catena configuration file Source code in catena/models/config.py 75 76 77 78 79 80 def cluster_profiles ( self ): \"\"\" Returns available cluster profiles defined in catena configuration file \"\"\" return list ( self . clusters . keys ())","title":"cluster_profiles()"},{"location":"models/config/#catena.models.config.CatenaConfig.get_profile","text":"Return configuration properties for the named cluster profile Source code in catena/models/config.py 83 84 85 86 87 88 89 90 91 def get_profile ( self , name : str ): \"\"\" Return configuration properties for the named cluster profile \"\"\" if name in self . clusters : return self . clusters . get ( name ) print ( f \"\u26a0\ufe0f [red] profile ' { name } ' does not exist[/red]\" ) print ( f \"Possiblities include: { self . cluster_profiles () } \" )","title":"get_profile()"},{"location":"models/config/#catena.models.config.CatenaConfig.read","text":"Read configuration from specified yaml file Source code in catena/models/config.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 @classmethod def read ( cls , path : Optional [ str ] = None ): \"\"\" Read configuration from specified yaml file \"\"\" if path is None : path = Path . home () / \".catena/conf.yml\" if not Path ( path ) . is_file (): print ( f \"\u26a0\ufe0f [red] file does not exist: { path } [/red]\" ) exit ( 1 ) # read manifest with open ( path , 'r' ) as f : data = safe_loader ( f , Loader = Loader ) return cls ( ** data )","title":"read()"},{"location":"models/config/#cluster-definition-model","text":"Bases: BaseModel Source code in catena/models/config.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 class ClusterDefinition ( BaseModel ): backend : Optional [ str ] = 'slurm' class Config : extra = Extra . allow arbitrary_types_allowed = True def __init__ ( self , ** kwargs ): super () . __init__ ( ** kwargs ) cluster_args = { k : v for k , v in kwargs . items () if k not in self . __fields__ } if self . backend == 'slurm' : slurm_cluster = SlurmCluster ( ** cluster_args ) for attr , val in slurm_cluster . dict () . items (): self . __dict__ [ attr ] = val self . _cluster = slurm_cluster","title":"Cluster Definition Model"},{"location":"models/config/#slurm-cluster-definition-model","text":"Bases: BaseModel Source code in catena/models/config.py 12 13 14 15 16 17 18 19 class SlurmCluster ( BaseModel ): api_host : str api_proto : Optional [ str ] = 'http' api_version : Optional [ str ] = '0.0.35' api_port : Optional [ str ] = '6820' class Config : api_version_compat = [ '0.0.35' ]","title":"SLURM Cluster Definition Model "},{"location":"models/extensions/","text":"ExtendedBaseModel Bases: BaseModel Source code in catena/models/extensions.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 class ExtendedBaseModel ( BaseModel ): @no_type_check def __setitem__ ( self , name : str , value : Any ): \"\"\" Dunder method for allowing setting attributes dictionary style Args: name: name of attribute to set value: value to set attribute to \"\"\" self . __setattr__ ( name , value ) @no_type_check def __eq__ ( self , other ): \"\"\" Dunder method for allowing comparison of Options instances. If two instances are the same will return True Args: other: other instance of Options to compare with \"\"\" # do not compare against unrelated types if not isinstance ( other , Options ): return NotImplemented return self . dict () == other . dict () def setdefault ( self , keyname : str , value : Any ): \"\"\" Analogue to `dict.setdefault(keyname, value)` for Pydantic models Will set the value of the corresponding attribute, `keyname` if it has not been set Args: keyname: name of attribute to set default value for value: value to set if attribute has not been set to a non-default value already \"\"\" if keyname not in self . __fields_set__ : self [ keyname ] = value return value else : return self . dict () . get ( keyname ) def pop ( self , keyname : str , value : Any = None ): \"\"\" Analogue to `dict.pop(keyname, value)` for Pydantic models Will remove the attribute from the model and return it's value if it has been set, otherwise it will return `value` Args: keyname: name of attribute to remove and return it's value value: value to return if `keyname` attribute has not been set to a non-default value \"\"\" _val = self . dict () . pop ( keyname , value ) delattr ( self , keyname ) if _val is None : return value else : return _val def get ( self , keyname : str , value : Any = None ): \"\"\" Analogue to `dict.get(keyname, value)` for Pydantic models Args: keyname: name of attribute for which to return the corresponding value value: value to return if `keyname` attribute has not been set to a non-default value \"\"\" if keyname not in self . __fields__set__ : return value else : return self . dict () . get ( keyname ) __eq__ ( other ) Dunder method for allowing comparison of Options instances. If two instances are the same will return True Parameters: Name Type Description Default other other instance of Options to compare with required Source code in catena/models/extensions.py 18 19 20 21 22 23 24 25 26 27 28 29 30 @no_type_check def __eq__ ( self , other ): \"\"\" Dunder method for allowing comparison of Options instances. If two instances are the same will return True Args: other: other instance of Options to compare with \"\"\" # do not compare against unrelated types if not isinstance ( other , Options ): return NotImplemented return self . dict () == other . dict () __setitem__ ( name , value ) Dunder method for allowing setting attributes dictionary style Parameters: Name Type Description Default name str name of attribute to set required value Any value to set attribute to required Source code in catena/models/extensions.py 7 8 9 10 11 12 13 14 15 16 @no_type_check def __setitem__ ( self , name : str , value : Any ): \"\"\" Dunder method for allowing setting attributes dictionary style Args: name: name of attribute to set value: value to set attribute to \"\"\" self . __setattr__ ( name , value ) get ( keyname , value = None ) Analogue to dict.get(keyname, value) for Pydantic models Parameters: Name Type Description Default keyname str name of attribute for which to return the corresponding value required value Any value to return if keyname attribute has not been set to a non-default value None Source code in catena/models/extensions.py 69 70 71 72 73 74 75 76 77 78 79 def get ( self , keyname : str , value : Any = None ): \"\"\" Analogue to `dict.get(keyname, value)` for Pydantic models Args: keyname: name of attribute for which to return the corresponding value value: value to return if `keyname` attribute has not been set to a non-default value \"\"\" if keyname not in self . __fields__set__ : return value else : return self . dict () . get ( keyname ) pop ( keyname , value = None ) Analogue to dict.pop(keyname, value) for Pydantic models Will remove the attribute from the model and return it's value if it has been set, otherwise it will return value Parameters: Name Type Description Default keyname str name of attribute to remove and return it's value required value Any value to return if keyname attribute has not been set to a non-default value None Source code in catena/models/extensions.py 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 def pop ( self , keyname : str , value : Any = None ): \"\"\" Analogue to `dict.pop(keyname, value)` for Pydantic models Will remove the attribute from the model and return it's value if it has been set, otherwise it will return `value` Args: keyname: name of attribute to remove and return it's value value: value to return if `keyname` attribute has not been set to a non-default value \"\"\" _val = self . dict () . pop ( keyname , value ) delattr ( self , keyname ) if _val is None : return value else : return _val setdefault ( keyname , value ) Analogue to dict.setdefault(keyname, value) for Pydantic models Will set the value of the corresponding attribute, keyname if it has not been set Parameters: Name Type Description Default keyname str name of attribute to set default value for required value Any value to set if attribute has not been set to a non-default value already required Source code in catena/models/extensions.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 def setdefault ( self , keyname : str , value : Any ): \"\"\" Analogue to `dict.setdefault(keyname, value)` for Pydantic models Will set the value of the corresponding attribute, `keyname` if it has not been set Args: keyname: name of attribute to set default value for value: value to set if attribute has not been set to a non-default value already \"\"\" if keyname not in self . __fields_set__ : self [ keyname ] = value return value else : return self . dict () . get ( keyname )","title":"Model Extensions"},{"location":"models/extensions/#extendedbasemodel","text":"Bases: BaseModel Source code in catena/models/extensions.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 class ExtendedBaseModel ( BaseModel ): @no_type_check def __setitem__ ( self , name : str , value : Any ): \"\"\" Dunder method for allowing setting attributes dictionary style Args: name: name of attribute to set value: value to set attribute to \"\"\" self . __setattr__ ( name , value ) @no_type_check def __eq__ ( self , other ): \"\"\" Dunder method for allowing comparison of Options instances. If two instances are the same will return True Args: other: other instance of Options to compare with \"\"\" # do not compare against unrelated types if not isinstance ( other , Options ): return NotImplemented return self . dict () == other . dict () def setdefault ( self , keyname : str , value : Any ): \"\"\" Analogue to `dict.setdefault(keyname, value)` for Pydantic models Will set the value of the corresponding attribute, `keyname` if it has not been set Args: keyname: name of attribute to set default value for value: value to set if attribute has not been set to a non-default value already \"\"\" if keyname not in self . __fields_set__ : self [ keyname ] = value return value else : return self . dict () . get ( keyname ) def pop ( self , keyname : str , value : Any = None ): \"\"\" Analogue to `dict.pop(keyname, value)` for Pydantic models Will remove the attribute from the model and return it's value if it has been set, otherwise it will return `value` Args: keyname: name of attribute to remove and return it's value value: value to return if `keyname` attribute has not been set to a non-default value \"\"\" _val = self . dict () . pop ( keyname , value ) delattr ( self , keyname ) if _val is None : return value else : return _val def get ( self , keyname : str , value : Any = None ): \"\"\" Analogue to `dict.get(keyname, value)` for Pydantic models Args: keyname: name of attribute for which to return the corresponding value value: value to return if `keyname` attribute has not been set to a non-default value \"\"\" if keyname not in self . __fields__set__ : return value else : return self . dict () . get ( keyname )","title":"ExtendedBaseModel"},{"location":"models/extensions/#catena.models.extensions.ExtendedBaseModel.__eq__","text":"Dunder method for allowing comparison of Options instances. If two instances are the same will return True Parameters: Name Type Description Default other other instance of Options to compare with required Source code in catena/models/extensions.py 18 19 20 21 22 23 24 25 26 27 28 29 30 @no_type_check def __eq__ ( self , other ): \"\"\" Dunder method for allowing comparison of Options instances. If two instances are the same will return True Args: other: other instance of Options to compare with \"\"\" # do not compare against unrelated types if not isinstance ( other , Options ): return NotImplemented return self . dict () == other . dict ()","title":"__eq__()"},{"location":"models/extensions/#catena.models.extensions.ExtendedBaseModel.__setitem__","text":"Dunder method for allowing setting attributes dictionary style Parameters: Name Type Description Default name str name of attribute to set required value Any value to set attribute to required Source code in catena/models/extensions.py 7 8 9 10 11 12 13 14 15 16 @no_type_check def __setitem__ ( self , name : str , value : Any ): \"\"\" Dunder method for allowing setting attributes dictionary style Args: name: name of attribute to set value: value to set attribute to \"\"\" self . __setattr__ ( name , value )","title":"__setitem__()"},{"location":"models/extensions/#catena.models.extensions.ExtendedBaseModel.get","text":"Analogue to dict.get(keyname, value) for Pydantic models Parameters: Name Type Description Default keyname str name of attribute for which to return the corresponding value required value Any value to return if keyname attribute has not been set to a non-default value None Source code in catena/models/extensions.py 69 70 71 72 73 74 75 76 77 78 79 def get ( self , keyname : str , value : Any = None ): \"\"\" Analogue to `dict.get(keyname, value)` for Pydantic models Args: keyname: name of attribute for which to return the corresponding value value: value to return if `keyname` attribute has not been set to a non-default value \"\"\" if keyname not in self . __fields__set__ : return value else : return self . dict () . get ( keyname )","title":"get()"},{"location":"models/extensions/#catena.models.extensions.ExtendedBaseModel.pop","text":"Analogue to dict.pop(keyname, value) for Pydantic models Will remove the attribute from the model and return it's value if it has been set, otherwise it will return value Parameters: Name Type Description Default keyname str name of attribute to remove and return it's value required value Any value to return if keyname attribute has not been set to a non-default value None Source code in catena/models/extensions.py 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 def pop ( self , keyname : str , value : Any = None ): \"\"\" Analogue to `dict.pop(keyname, value)` for Pydantic models Will remove the attribute from the model and return it's value if it has been set, otherwise it will return `value` Args: keyname: name of attribute to remove and return it's value value: value to return if `keyname` attribute has not been set to a non-default value \"\"\" _val = self . dict () . pop ( keyname , value ) delattr ( self , keyname ) if _val is None : return value else : return _val","title":"pop()"},{"location":"models/extensions/#catena.models.extensions.ExtendedBaseModel.setdefault","text":"Analogue to dict.setdefault(keyname, value) for Pydantic models Will set the value of the corresponding attribute, keyname if it has not been set Parameters: Name Type Description Default keyname str name of attribute to set default value for required value Any value to set if attribute has not been set to a non-default value already required Source code in catena/models/extensions.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 def setdefault ( self , keyname : str , value : Any ): \"\"\" Analogue to `dict.setdefault(keyname, value)` for Pydantic models Will set the value of the corresponding attribute, `keyname` if it has not been set Args: keyname: name of attribute to set default value for value: value to set if attribute has not been set to a non-default value already \"\"\" if keyname not in self . __fields_set__ : self [ keyname ] = value return value else : return self . dict () . get ( keyname )","title":"setdefault()"},{"location":"models/job_manifests/","text":"JobManifest Bases: ExtendedBaseModel Model for parsing job manifests: describes the expected layout of a job manifest and provides methods for returning job definitions that can be used to initialize a slurmjobs job instance (currently, SlurmJob) Add validator to ensure that depencies for a job do not list the job itself as a dependency. Attributes: Name Type Description job_options Optional [ List [ JobOptions ]] section of YML job manifest for defining global job options as a list. Global job options are tagged using anchors and referenced within a given job's job definition, under the job field. All job options that jobs Optional [ List [ Job ]] list of instances of JobDefinition Source code in catena/models/job_manifest.py 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 class JobManifest ( ExtendedBaseModel ): \"\"\" Model for parsing job manifests: describes the expected layout of a job manifest and provides methods for returning job definitions that can be used to initialize a `slurmjobs` job instance (currently, SlurmJob) TODO: Add validator to ensure that depencies for a job do not list the job itself as a dependency. Attributes: job_options: section of YML job manifest for defining global job options as a list. Global job options are tagged using anchors and referenced within a given job's job definition, under the `job` field. All job options that jobs: list of instances of JobDefinition \"\"\" cluster_profile : str catena_config : Optional [ str ] = str ( Path () . home () / '.catena/conf.yml' ) version : Optional [ str ] = \"1.0\" job_options : Optional [ List [ JobOptions ]] jobs : Optional [ List [ Job ]] class Config : \"\"\" `JobManifest` model `Config` sub-class: can be accessed internally as `self.Config` or `JobManifest.Config`. The config class of a Pydantic model is also passed as a kwarg to validators and acts as a useful means of storing external variables that are accesible to field validators. Attributes: ext_opts: extra job options that are separate from SLURM job options. This difference is abstracted to the user, but is managed internally. \"\"\" ext_opts : list = [ 'env_modules' , 'job_script' , 'env_extra' , 'job_script_args' , 'command' , 'dependencies' ] def __filter_ext_opts ( self , jobdef : JobOptions , field : str ): \"\"\" Filter non sbatch options from job (global opts) field. Local job opts will always take precedence over those defined globally \"\"\" field_val = None if ( jobdef . job . dict () . get ( field ) is not None and jobdef . dict () . get ( field ) is not None ): field_val = jobdef . pop ( field ) jobdef . job . pop ( field ) elif jobdef . job . dict () . get ( field ) is not None : #and field_val = jobdef . job . pop ( field ) else : field_val = jobdef . pop ( field ) return jobdef , field_val def expand_jobs ( self ): \"\"\" Return list of job definitions processed from a initialized instance of `self` or `JobManifest`. The fields defined within this model can be passed to an instance of a `slurmjobs` Job. For example, the [SLURMRESTJob](../jobs/slurmrestjob.md) object. \"\"\" jobs = [] filtered_opts = {} # iterate over all job definitions for jobblock in self . jobs : for jobname , jobdef in jobblock . __root__ . items (): # create named tuple for storing unset/set options and there default values Options = namedtuple ( 'Options' , 'name default' ) # collect set job options on local and global levels local_opts_set = jobdef . __fields_set__ global_opts_set = jobdef . __fields_set__ fields = jobdef . job . __fields__ # set job name jobdef . name = jobname # create copy of job excluding env_modules property tmpjob = JobOptions ( ** { k : v for k , v in jobdef . job . dict () . items () if k != 'env_modules' }) tmpjob = JobOptions ( ** jobdef . job . dict ()) # filter external options for optname in self . Config . ext_opts : jobdef , optval = self . __filter_ext_opts ( jobdef , optname ) filtered_opts [ optname ] = optval # list all set field names and default values for non-required fields setfields = [ Options ( x , fields [ x ] . default ) for x in fields . keys () if x in global_opts_set ] for opt in setfields : if opt . name in jobdef . dict (): tmpjob [ opt . name ] = jobdef . pop ( opt . name ) # add ext opts back into job def for optname , optval in filtered_opts . items (): jobdef [ optname ] = optval tmpjob . pop ( optname ) # set job properties after filtering jobdef [ 'job' ] = tmpjob jobs . append ( jobdef ) return jobs Config JobManifest model Config sub-class: can be accessed internally as self.Config or JobManifest.Config . The config class of a Pydantic model is also passed as a kwarg to validators and acts as a useful means of storing external variables that are accesible to field validators. Attributes: Name Type Description ext_opts list extra job options that are separate from SLURM job options. This difference is abstracted to the user, but is managed internally. Source code in catena/models/job_manifest.py 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 class Config : \"\"\" `JobManifest` model `Config` sub-class: can be accessed internally as `self.Config` or `JobManifest.Config`. The config class of a Pydantic model is also passed as a kwarg to validators and acts as a useful means of storing external variables that are accesible to field validators. Attributes: ext_opts: extra job options that are separate from SLURM job options. This difference is abstracted to the user, but is managed internally. \"\"\" ext_opts : list = [ 'env_modules' , 'job_script' , 'env_extra' , 'job_script_args' , 'command' , 'dependencies' ] __filter_ext_opts ( jobdef , field ) Filter non sbatch options from job (global opts) field. Local job opts will always take precedence over those defined globally Source code in catena/models/job_manifest.py 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 def __filter_ext_opts ( self , jobdef : JobOptions , field : str ): \"\"\" Filter non sbatch options from job (global opts) field. Local job opts will always take precedence over those defined globally \"\"\" field_val = None if ( jobdef . job . dict () . get ( field ) is not None and jobdef . dict () . get ( field ) is not None ): field_val = jobdef . pop ( field ) jobdef . job . pop ( field ) elif jobdef . job . dict () . get ( field ) is not None : #and field_val = jobdef . job . pop ( field ) else : field_val = jobdef . pop ( field ) return jobdef , field_val expand_jobs () Return list of job definitions processed from a initialized instance of self or JobManifest . The fields defined within this model can be passed to an instance of a slurmjobs Job. For example, the SLURMRESTJob object. Source code in catena/models/job_manifest.py 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 def expand_jobs ( self ): \"\"\" Return list of job definitions processed from a initialized instance of `self` or `JobManifest`. The fields defined within this model can be passed to an instance of a `slurmjobs` Job. For example, the [SLURMRESTJob](../jobs/slurmrestjob.md) object. \"\"\" jobs = [] filtered_opts = {} # iterate over all job definitions for jobblock in self . jobs : for jobname , jobdef in jobblock . __root__ . items (): # create named tuple for storing unset/set options and there default values Options = namedtuple ( 'Options' , 'name default' ) # collect set job options on local and global levels local_opts_set = jobdef . __fields_set__ global_opts_set = jobdef . __fields_set__ fields = jobdef . job . __fields__ # set job name jobdef . name = jobname # create copy of job excluding env_modules property tmpjob = JobOptions ( ** { k : v for k , v in jobdef . job . dict () . items () if k != 'env_modules' }) tmpjob = JobOptions ( ** jobdef . job . dict ()) # filter external options for optname in self . Config . ext_opts : jobdef , optval = self . __filter_ext_opts ( jobdef , optname ) filtered_opts [ optname ] = optval # list all set field names and default values for non-required fields setfields = [ Options ( x , fields [ x ] . default ) for x in fields . keys () if x in global_opts_set ] for opt in setfields : if opt . name in jobdef . dict (): tmpjob [ opt . name ] = jobdef . pop ( opt . name ) # add ext opts back into job def for optname , optval in filtered_opts . items (): jobdef [ optname ] = optval tmpjob . pop ( optname ) # set job properties after filtering jobdef [ 'job' ] = tmpjob jobs . append ( jobdef ) return jobs JobOptions Bases: SlurmSubmit Job options schema for job manifest. Extends SlurmSubmit which provides attributes corresponding to sbatch options in SLURM. Attributes: Name Type Description name Optional [ str ] job name as it will appear in SLURM queue (the root key of a given Job is usually set internally as the job name when parsing a manifest) env_modules Optional [ List [ str ]] list module names that should be loaded when submitting the job to a SLURM scheduler and made available to the environment running the job. For example, ['anaconda3/2021.11', 'matlab/96'] env_extra Optional [ Dict [ str , Any ]] dictionary of extra environment variables to export to the environment running the job submitted to a SLURM scheduler. For example, {'MYVAR': '/path/to/stuff'} . See how to append, prepend, or replace job_script Optional [ str ] path to the script, either relative or absolute. The ~ is also excepted and converted to the appropriate absolute path for the current users directory. If using relative paths, be sure to understand where the paths should be relative to, to appropriately locate your scripts. job_script_args Optional [ List [ str ]] list of arguments to pass to the job_script when it is executed. For example, job_script_args=['--version'] command Optional [ str ] custom command to use when running job_script . If defined, the the script provided will be run as an executable with this command prepended. For example, command='python -m' would result in the job_script being called as: python -m <job_script> . Generally, the default should give the right result. Source code in catena/models/job_manifest.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 class JobOptions ( SlurmSubmit ): \"\"\" Job options schema for job manifest. Extends SlurmSubmit which provides attributes corresponding to sbatch options in SLURM. Attributes: name: job name as it will appear in SLURM queue (the __root__ key of a given Job is usually set internally as the job name when parsing a manifest) env_modules: list module names that should be loaded when submitting the job to a SLURM scheduler and made available to the environment running the job. For example, `['anaconda3/2021.11', 'matlab/96']` env_extra: dictionary of extra environment variables to export to the environment running the job submitted to a SLURM scheduler. For example, `{'MYVAR': '/path/to/stuff'}`. See how to [append, prepend, or replace](../examples/example1.md#env_extra_feats) job_script: path to the script, either relative or absolute. The `~` is also excepted and converted to the appropriate absolute path for the current users directory. ***If*** using relative paths, be sure to understand where the paths should be relative to, to appropriately locate your scripts. job_script_args: list of arguments to pass to the job_script when it is executed. For example, `job_script_args=['--version']` command: custom command to use when running `job_script`. If defined, the the script provided will be run as an executable with this command prepended. For example, command='python -m' would result in the `job_script` being called as: `python -m <job_script>`. Generally, the default should give the right result. \"\"\" name : Optional [ str ] env_modules : Optional [ List [ str ]] = None env_extra : Optional [ Dict [ str , Any ]] = None job_script : Optional [ str ] job_script_args : Optional [ List [ str ]] = None command : Optional [ str ] dependencies : Optional [ Dict [ DependencyType , Union [ str , List [ str ]]]] @validator ( 'job_script' ) def expand_home_shortcut ( cls , v ): if v is not None : if str ( v . startswith ( '~' )): ppath = Path ( v ) return str ( ppath . expanduser ()) else : return v else : return v JobDefinition Bases: JobOptions Local job definition that extends JobOptions as well as provides a field, job, for referencing global JobOptions (using YML anchors/aliases) Attributes: Name Type Description job Optional [ JobOptions ] global job options parsed from YML anchors/aliases. Ultimately local and global job options are combined when defining a given Job to be submitted to a SLURM cluster, with local job options taking precendence over global Source code in catena/models/job_manifest.py 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 class JobDefinition ( JobOptions ): \"\"\" Local job definition that extends JobOptions as well as provides a field, job, for referencing global JobOptions (using YML anchors/aliases) Attributes: job: global job options parsed from YML anchors/aliases. Ultimately local and global job options are combined when defining a given Job to be submitted to a SLURM cluster, with local job options taking precendence over global \"\"\" job : Optional [ JobOptions ]","title":"Job Manifests"},{"location":"models/job_manifests/#jobmanifest","text":"Bases: ExtendedBaseModel Model for parsing job manifests: describes the expected layout of a job manifest and provides methods for returning job definitions that can be used to initialize a slurmjobs job instance (currently, SlurmJob) Add validator to ensure that depencies for a job do not list the job itself as a dependency. Attributes: Name Type Description job_options Optional [ List [ JobOptions ]] section of YML job manifest for defining global job options as a list. Global job options are tagged using anchors and referenced within a given job's job definition, under the job field. All job options that jobs Optional [ List [ Job ]] list of instances of JobDefinition Source code in catena/models/job_manifest.py 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 class JobManifest ( ExtendedBaseModel ): \"\"\" Model for parsing job manifests: describes the expected layout of a job manifest and provides methods for returning job definitions that can be used to initialize a `slurmjobs` job instance (currently, SlurmJob) TODO: Add validator to ensure that depencies for a job do not list the job itself as a dependency. Attributes: job_options: section of YML job manifest for defining global job options as a list. Global job options are tagged using anchors and referenced within a given job's job definition, under the `job` field. All job options that jobs: list of instances of JobDefinition \"\"\" cluster_profile : str catena_config : Optional [ str ] = str ( Path () . home () / '.catena/conf.yml' ) version : Optional [ str ] = \"1.0\" job_options : Optional [ List [ JobOptions ]] jobs : Optional [ List [ Job ]] class Config : \"\"\" `JobManifest` model `Config` sub-class: can be accessed internally as `self.Config` or `JobManifest.Config`. The config class of a Pydantic model is also passed as a kwarg to validators and acts as a useful means of storing external variables that are accesible to field validators. Attributes: ext_opts: extra job options that are separate from SLURM job options. This difference is abstracted to the user, but is managed internally. \"\"\" ext_opts : list = [ 'env_modules' , 'job_script' , 'env_extra' , 'job_script_args' , 'command' , 'dependencies' ] def __filter_ext_opts ( self , jobdef : JobOptions , field : str ): \"\"\" Filter non sbatch options from job (global opts) field. Local job opts will always take precedence over those defined globally \"\"\" field_val = None if ( jobdef . job . dict () . get ( field ) is not None and jobdef . dict () . get ( field ) is not None ): field_val = jobdef . pop ( field ) jobdef . job . pop ( field ) elif jobdef . job . dict () . get ( field ) is not None : #and field_val = jobdef . job . pop ( field ) else : field_val = jobdef . pop ( field ) return jobdef , field_val def expand_jobs ( self ): \"\"\" Return list of job definitions processed from a initialized instance of `self` or `JobManifest`. The fields defined within this model can be passed to an instance of a `slurmjobs` Job. For example, the [SLURMRESTJob](../jobs/slurmrestjob.md) object. \"\"\" jobs = [] filtered_opts = {} # iterate over all job definitions for jobblock in self . jobs : for jobname , jobdef in jobblock . __root__ . items (): # create named tuple for storing unset/set options and there default values Options = namedtuple ( 'Options' , 'name default' ) # collect set job options on local and global levels local_opts_set = jobdef . __fields_set__ global_opts_set = jobdef . __fields_set__ fields = jobdef . job . __fields__ # set job name jobdef . name = jobname # create copy of job excluding env_modules property tmpjob = JobOptions ( ** { k : v for k , v in jobdef . job . dict () . items () if k != 'env_modules' }) tmpjob = JobOptions ( ** jobdef . job . dict ()) # filter external options for optname in self . Config . ext_opts : jobdef , optval = self . __filter_ext_opts ( jobdef , optname ) filtered_opts [ optname ] = optval # list all set field names and default values for non-required fields setfields = [ Options ( x , fields [ x ] . default ) for x in fields . keys () if x in global_opts_set ] for opt in setfields : if opt . name in jobdef . dict (): tmpjob [ opt . name ] = jobdef . pop ( opt . name ) # add ext opts back into job def for optname , optval in filtered_opts . items (): jobdef [ optname ] = optval tmpjob . pop ( optname ) # set job properties after filtering jobdef [ 'job' ] = tmpjob jobs . append ( jobdef ) return jobs","title":"JobManifest"},{"location":"models/job_manifests/#catena.models.job_manifest.JobManifest.Config","text":"JobManifest model Config sub-class: can be accessed internally as self.Config or JobManifest.Config . The config class of a Pydantic model is also passed as a kwarg to validators and acts as a useful means of storing external variables that are accesible to field validators. Attributes: Name Type Description ext_opts list extra job options that are separate from SLURM job options. This difference is abstracted to the user, but is managed internally. Source code in catena/models/job_manifest.py 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 class Config : \"\"\" `JobManifest` model `Config` sub-class: can be accessed internally as `self.Config` or `JobManifest.Config`. The config class of a Pydantic model is also passed as a kwarg to validators and acts as a useful means of storing external variables that are accesible to field validators. Attributes: ext_opts: extra job options that are separate from SLURM job options. This difference is abstracted to the user, but is managed internally. \"\"\" ext_opts : list = [ 'env_modules' , 'job_script' , 'env_extra' , 'job_script_args' , 'command' , 'dependencies' ]","title":"Config"},{"location":"models/job_manifests/#catena.models.job_manifest.JobManifest.__filter_ext_opts","text":"Filter non sbatch options from job (global opts) field. Local job opts will always take precedence over those defined globally Source code in catena/models/job_manifest.py 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 def __filter_ext_opts ( self , jobdef : JobOptions , field : str ): \"\"\" Filter non sbatch options from job (global opts) field. Local job opts will always take precedence over those defined globally \"\"\" field_val = None if ( jobdef . job . dict () . get ( field ) is not None and jobdef . dict () . get ( field ) is not None ): field_val = jobdef . pop ( field ) jobdef . job . pop ( field ) elif jobdef . job . dict () . get ( field ) is not None : #and field_val = jobdef . job . pop ( field ) else : field_val = jobdef . pop ( field ) return jobdef , field_val","title":"__filter_ext_opts()"},{"location":"models/job_manifests/#catena.models.job_manifest.JobManifest.expand_jobs","text":"Return list of job definitions processed from a initialized instance of self or JobManifest . The fields defined within this model can be passed to an instance of a slurmjobs Job. For example, the SLURMRESTJob object. Source code in catena/models/job_manifest.py 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 def expand_jobs ( self ): \"\"\" Return list of job definitions processed from a initialized instance of `self` or `JobManifest`. The fields defined within this model can be passed to an instance of a `slurmjobs` Job. For example, the [SLURMRESTJob](../jobs/slurmrestjob.md) object. \"\"\" jobs = [] filtered_opts = {} # iterate over all job definitions for jobblock in self . jobs : for jobname , jobdef in jobblock . __root__ . items (): # create named tuple for storing unset/set options and there default values Options = namedtuple ( 'Options' , 'name default' ) # collect set job options on local and global levels local_opts_set = jobdef . __fields_set__ global_opts_set = jobdef . __fields_set__ fields = jobdef . job . __fields__ # set job name jobdef . name = jobname # create copy of job excluding env_modules property tmpjob = JobOptions ( ** { k : v for k , v in jobdef . job . dict () . items () if k != 'env_modules' }) tmpjob = JobOptions ( ** jobdef . job . dict ()) # filter external options for optname in self . Config . ext_opts : jobdef , optval = self . __filter_ext_opts ( jobdef , optname ) filtered_opts [ optname ] = optval # list all set field names and default values for non-required fields setfields = [ Options ( x , fields [ x ] . default ) for x in fields . keys () if x in global_opts_set ] for opt in setfields : if opt . name in jobdef . dict (): tmpjob [ opt . name ] = jobdef . pop ( opt . name ) # add ext opts back into job def for optname , optval in filtered_opts . items (): jobdef [ optname ] = optval tmpjob . pop ( optname ) # set job properties after filtering jobdef [ 'job' ] = tmpjob jobs . append ( jobdef ) return jobs","title":"expand_jobs()"},{"location":"models/job_manifests/#joboptions","text":"Bases: SlurmSubmit Job options schema for job manifest. Extends SlurmSubmit which provides attributes corresponding to sbatch options in SLURM. Attributes: Name Type Description name Optional [ str ] job name as it will appear in SLURM queue (the root key of a given Job is usually set internally as the job name when parsing a manifest) env_modules Optional [ List [ str ]] list module names that should be loaded when submitting the job to a SLURM scheduler and made available to the environment running the job. For example, ['anaconda3/2021.11', 'matlab/96'] env_extra Optional [ Dict [ str , Any ]] dictionary of extra environment variables to export to the environment running the job submitted to a SLURM scheduler. For example, {'MYVAR': '/path/to/stuff'} . See how to append, prepend, or replace job_script Optional [ str ] path to the script, either relative or absolute. The ~ is also excepted and converted to the appropriate absolute path for the current users directory. If using relative paths, be sure to understand where the paths should be relative to, to appropriately locate your scripts. job_script_args Optional [ List [ str ]] list of arguments to pass to the job_script when it is executed. For example, job_script_args=['--version'] command Optional [ str ] custom command to use when running job_script . If defined, the the script provided will be run as an executable with this command prepended. For example, command='python -m' would result in the job_script being called as: python -m <job_script> . Generally, the default should give the right result. Source code in catena/models/job_manifest.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 class JobOptions ( SlurmSubmit ): \"\"\" Job options schema for job manifest. Extends SlurmSubmit which provides attributes corresponding to sbatch options in SLURM. Attributes: name: job name as it will appear in SLURM queue (the __root__ key of a given Job is usually set internally as the job name when parsing a manifest) env_modules: list module names that should be loaded when submitting the job to a SLURM scheduler and made available to the environment running the job. For example, `['anaconda3/2021.11', 'matlab/96']` env_extra: dictionary of extra environment variables to export to the environment running the job submitted to a SLURM scheduler. For example, `{'MYVAR': '/path/to/stuff'}`. See how to [append, prepend, or replace](../examples/example1.md#env_extra_feats) job_script: path to the script, either relative or absolute. The `~` is also excepted and converted to the appropriate absolute path for the current users directory. ***If*** using relative paths, be sure to understand where the paths should be relative to, to appropriately locate your scripts. job_script_args: list of arguments to pass to the job_script when it is executed. For example, `job_script_args=['--version']` command: custom command to use when running `job_script`. If defined, the the script provided will be run as an executable with this command prepended. For example, command='python -m' would result in the `job_script` being called as: `python -m <job_script>`. Generally, the default should give the right result. \"\"\" name : Optional [ str ] env_modules : Optional [ List [ str ]] = None env_extra : Optional [ Dict [ str , Any ]] = None job_script : Optional [ str ] job_script_args : Optional [ List [ str ]] = None command : Optional [ str ] dependencies : Optional [ Dict [ DependencyType , Union [ str , List [ str ]]]] @validator ( 'job_script' ) def expand_home_shortcut ( cls , v ): if v is not None : if str ( v . startswith ( '~' )): ppath = Path ( v ) return str ( ppath . expanduser ()) else : return v else : return v","title":"JobOptions"},{"location":"models/job_manifests/#jobdefinition","text":"Bases: JobOptions Local job definition that extends JobOptions as well as provides a field, job, for referencing global JobOptions (using YML anchors/aliases) Attributes: Name Type Description job Optional [ JobOptions ] global job options parsed from YML anchors/aliases. Ultimately local and global job options are combined when defining a given Job to be submitted to a SLURM cluster, with local job options taking precendence over global Source code in catena/models/job_manifest.py 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 class JobDefinition ( JobOptions ): \"\"\" Local job definition that extends JobOptions as well as provides a field, job, for referencing global JobOptions (using YML anchors/aliases) Attributes: job: global job options parsed from YML anchors/aliases. Ultimately local and global job options are combined when defining a given Job to be submitted to a SLURM cluster, with local job options taking precendence over global \"\"\" job : Optional [ JobOptions ]","title":"JobDefinition"},{"location":"models/slurm_job_models/","text":"SLURM Job Schemas SlurmModel Bases: BaseModel General SLURM job model including job options and the job script path, used for submitting a job through the REST API: POST job/{jobid} Attributes: Name Type Description script str full absolute path to script to be submitted as a job to the SLURM cluster job SlurmSubmit SLURM sbatch options for the associated job Source code in catena/models/slurm_submit.py 224 225 226 227 228 229 230 231 232 233 234 235 class SlurmModel ( BaseModel ): \"\"\" General SLURM job model including job options and the job script path, used for submitting a job through the REST API: <code>POST job/{jobid}</code> Attributes: script: full absolute path to script to be submitted as a job to the SLURM cluster job: SLURM sbatch options for the associated job \"\"\" script : str job : SlurmSubmit = Field ( ... ) SlurmSubmit Bases: ExtendedBaseModel SLURM sbatch options: see SLURM documentation for more details. Attributes: Name Type Description name str SLURM job name delay_boot Optional [ int ] do not reboot nodes in order to satisfied this job's feature specification if the job has been eligible to run for less than this time period, defaults to 0 (suggested to leave as default) dependency Optional [ str ] defer the start of this job until the specified dependencies have been satisfied completed. All dependencies must be satisfied if the ','separator is used. Dependencies are given in the format: --dependency= (list of jobids is colon-separated, indvidual dependencies are comma-separated). Any dependency may be satisfied if the \"?\" separator is used, defaults to None distribution Optional [ str ] specify alternate distribution methods for remote processes. In sbatch, this only sets environment variables that will be used by subsequent srun requests, defaults to 'arbitrary' environment Optional [ dict ] map of systems path to be set within the users environment when running the SLURM job, defaults to None exclusive Optional [ str ] The job allocation can not share nodes with other running jobs (or just other users with the '=user' option or with the '=mcs' option), defaults to 'user' get_user_environment Optional [ str ] this option will tell sbatch to retrieve the login environment variables for the user specified in the --uid option, defaults to None gres Optional [ str ] specifies a comma delimited list of generic consumable resources, defaults to None gres_flags Optional [ str ] specify generic and resource task binding options ( disable-binding/enforce-bindings ), defaults to 'disable-binding' gpu_binding Optional [ str ] bind tasks to specific GPUs. By default every spawned task can access every GPU allocated to the step, defaults to 'closest' gpu_frequency Optional [ str ] request that GPUs allocated to the job are configured with specific frequency values. This option can be used to independently configure the GPU and its memory frequencies, defaults to 'medium' gpus Optional [ str ] specify the total number of gpus required for the job ' :number', defaults to None gpus_per_node Optional [ str ] specify the number of GPUs required for the job on each node included in the job's resource allocation, defaults to None gpus_per_socket Optional [ str ] specify the number of GPUs required for the job on each socket included in the job's resource allocation. An optional GPU type specification can be supplied, defaults to None gpus_per_task Optional [ str ] specify the number of GPUs required for the job on each task to be spawned in the job's resource allocation. An optional GPU type specification can be supplied hold Optional [ str ] specify the job is to be submitted in a held state (priority of zero). A held job can now be released using scontrol to reset its priority (e.g. 'scontrol release '), defaults to false licenses Optional [ str ] specification of licenses (or other resources available on all nodes of the cluster) which must be allocated to this job. License names can be followed by a colon and count (the default count is one). Multiple license names should be comma separated (e.g. '--licenses=foo:4,bar') mail_type Optional [ str ] notify user by email when certain event types occur, defaults to 'NONE' (see SLURM documentation for full list of options) mail_user Optional [ str ] user to receive e-mail notification of state changes defined by --mail-type , defaylts as None memory_binding Optional [ str ] bind tasks to memory. Used only when the task/affinity plugin is enabled and the NUMA memory functions are available, defaults to None . memory_per_cpu Optional [ str ] minimum memory required per allocated CPU (default units are MB, different units can be specified using the suffix [K|M|G|T]), defaults to 0 memory_per_gpu Optional [ str ] minimum memory required per allocated GPU (default units are megabytes, different units can be specified using the suffix [K|M|G|T]), defaults to 0 memory_per_node Optional [ str ] specify the real memory required per node (default units are megabytes, different units can be specified using the suffix [K|M|G|T]), defaults to 0 cpus_per_task Optional [ int ] advise the SLURM controller that ensuing job steps will require ncpus number of processors per task. Without this option, the controller will just try to allocate one processor per task, defaults to 0 minimum_cpus_per_node Optional [ str ] specify a minimum number of logical cpus/processors per node, defaults to 0 minimum_nodes Optional [ str ] if a range of node counts is given, prefer the smaller count, defaults to 'true' nice Optional [ str ] run the job with an adjusted scheduling priority within Slurm. With no adjustment value the scheduling priority is decreased by 100. A negative nice value increases the priority, otherwise decreases it, defaults to None no_kill Optional [ str ] do not automatically terminate a job if one of the nodes it has been allocated fails. The user will assume the responsibilities for fault-tolerance should a node fail. When there is a node failure, any active job steps (usually MPI jobs) on that node will almost certainly suffer a fatal error, but with --no-kill , the job allocation will not be revoked so the user may launch new job steps on the remaining nodes in their allocation, defaults to 'off' nodes Optional [ int ] Request that a minimum of minnodes nodes be allocated to this job. A maximum node count may also be specified with maxnodes. If only one number is specified, this is used as both the minimum and maximum node count. The partition's node limits supersede those of the job. If a job's node limits are outside of the range permitted for its associated partition, the job will be left in a PENDING state, defaults to 1 open_mode Optional [ str ] (append|truncate) open the output and error files using append or truncate mode as specified. The default value is specified by the system configuration parameter JobFileAppend, defaults to 'append' partition Optional [ str ] request a specific partition for the resource allocation, defaults to 'normal' qos Optional [ str ] request a quality of service for the job, defaults to 'user' requeue Optional [ str ] specifies that the batch job should be eligible for requeuing, defaults to 'true' reservation Optional [ str ] allocate resources for the job from the named reservation, defaults to None sockets_per_node Optional [ int ] restrict node selection to nodes with at least the specified number of socket, defaults to 0 spread_job Optional [ str ] Spread the job allocation over as many nodes as possible and attempt to evenly distribute tasks across the allocated nodes (this option disables the topology/tree plugin), defaults to 'true' standard_error Optional [ str ] instruct SLURM to connect the batch script's standard error directly to the file name at the specified path, defaults to None standard_in Optional [ str ] instruct Slurm to connect the batch script's standard input directly to the file name at the specified path, defaults to None standard_out Optional [ str ] instruct Slurm to connect the batch script's standard output directly to the file name at the specified path, defaults to None tasks Optional [ int ] sbatch does not launch tasks, it requests an allocation of resources and submits a batch script. This option advises the SLURM controller that job steps run within the allocation will launch a maximum of number tasks and to provide for sufficient resources, **defaults to 1 task per node, but note that the --cpus-per-task option will change this default. tasks_per_core Optional [ int ] request the maximum ntasks be invoked on each core (meant to be used with the --ntasks option), defaults to 0 tasks_per_node Optional [ int ] r that ntasks be invoked on each node (if used with the --ntasks option, the --ntasks option will take precedence and the --ntasks-per-node will be treated as a maximum count of tasks per node), defaults to 0 tasks_per_socket Optional [ int ] request the maximum ntasks be invoked on each socket (meant to be used with the --ntasks option), defaults to 0 threads_per_core Optional [ int ] restrict node selection to nodes with at least the specified number of threads per core. In task layout, use the specified maximum number of threads per core, defaults to 0 time_limit Optional [ Union [ int , str ]] set a limit on the total run time of the job allocation, defaults to None wait_all_nodes Optional [ str ] (0|1) controls when the execution of the command begins, defaults to 0 (the job will begin execution as soon as wckey Optional [ str ] specify wckey to be used with job, defaults to None cores_per_socket Optional [ int ] restrict node selection to nodes with at least the specified number of cores per socket, defaults to None core_specifications Optional [ int ] count of specialized cores per node reserved by the job for system operations and not used by the application, defaults to None Source code in catena/models/slurm_submit.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 class SlurmSubmit ( ExtendedBaseModel ): \"\"\" SLURM sbatch options: see [SLURM documentation](https://slurm.schedmd.com/sbatch.html) for more details. Attributes: name: SLURM job name delay_boot: do not reboot nodes in order to satisfied this job's feature specification if the job has been eligible to run for less than this time period, **defaults to 0** (suggested to leave as default) dependency: defer the start of this job until the specified dependencies have been satisfied completed. All dependencies must be satisfied if the ','separator is used. Dependencies are given in the format: --dependency=<type:jobid[:jobid], type:jobid2[:jobid2].....> (list of jobids is colon-separated, indvidual dependencies are comma-separated). Any dependency may be satisfied if the \"?\" separator is used, **defaults to None** distribution: specify alternate distribution methods for remote processes. In sbatch, this only sets environment variables that will be used by subsequent srun requests, **defaults to 'arbitrary'** environment: map of systems path to be set within the users environment when running the SLURM job, **defaults to None** exclusive: The job allocation can not share nodes with other running jobs (or just other users with the '=user' option or with the '=mcs' option), **defaults to 'user'** get_user_environment: this option will tell sbatch to retrieve the login environment variables for the user specified in the <code>--uid</code> option, **defaults to None** gres: specifies a comma delimited list of generic consumable resources, **defaults to None** gres_flags: specify generic and resource task binding options (<code>disable-binding/enforce-bindings</code>), **defaults to 'disable-binding'** gpu_binding: bind tasks to specific GPUs. By default every spawned task can access every GPU allocated to the step, **defaults to 'closest'** gpu_frequency: request that GPUs allocated to the job are configured with specific frequency values. This option can be used to independently configure the GPU and its memory frequencies, **defaults to 'medium'** gpus: specify the total number of gpus required for the job '<type>:number', **defaults to None** gpus_per_node: specify the number of GPUs required for the job on each node included in the job's resource allocation, **defaults to None** gpus_per_socket: specify the number of GPUs required for the job on each socket included in the job's resource allocation. An optional GPU type specification can be supplied, **defaults to None** gpus_per_task: specify the number of GPUs required for the job on each task to be spawned in the job's resource allocation. An optional GPU type specification can be supplied hold: specify the job is to be submitted in a held state (priority of zero). A held job can now be released using scontrol to reset its priority (e.g. 'scontrol release <job_id>'), **defaults to false** licenses: specification of licenses (or other resources available on all nodes of the cluster) which must be allocated to this job. License names can be followed by a colon and count (the default count is one). Multiple license names should be comma separated (e.g. '--licenses=foo:4,bar') mail_type: notify user by email when certain event types occur, **defaults to 'NONE'** (see SLURM documentation for full list of options) mail_user: user to receive e-mail notification of state changes defined by <code>--mail-type</code>, **defaylts as None** memory_binding: bind tasks to memory. Used only when the task/affinity plugin is enabled and the NUMA memory functions are available, **defaults to None**. memory_per_cpu: minimum memory required per allocated CPU (default units are MB, different units can be specified using the suffix [K|M|G|T]), **defaults to 0** memory_per_gpu: minimum memory required per allocated GPU (default units are megabytes, different units can be specified using the suffix [K|M|G|T]), **defaults to 0** memory_per_node: specify the real memory required per node (default units are megabytes, different units can be specified using the suffix [K|M|G|T]), **defaults to 0** cpus_per_task: advise the SLURM controller that ensuing job steps will require ncpus number of processors per task. Without this option, the controller will just try to allocate one processor per task, **defaults to 0** minimum_cpus_per_node: specify a minimum number of logical cpus/processors per node, **defaults to 0** minimum_nodes: if a range of node counts is given, prefer the smaller count, **defaults to 'true'** nice: run the job with an adjusted scheduling priority within Slurm. With no adjustment value the scheduling priority is decreased by 100. A negative nice value increases the priority, otherwise decreases it, **defaults to None** no_kill: do not automatically terminate a job if one of the nodes it has been allocated fails. The user will assume the responsibilities for fault-tolerance should a node fail. When there is a node failure, any active job steps (usually MPI jobs) on that node will almost certainly suffer a fatal error, but with <code>--no-kill</code>, the job allocation will not be revoked so the user may launch new job steps on the remaining nodes in their allocation, **defaults to 'off'** nodes: Request that a minimum of minnodes nodes be allocated to this job. A maximum node count may also be specified with maxnodes. If only one number is specified, this is used as both the minimum and maximum node count. The partition's node limits supersede those of the job. If a job's node limits are outside of the range permitted for its associated partition, the job will be left in a PENDING state, **defaults to 1** open_mode: (append|truncate) open the output and error files using append or truncate mode as specified. The default value is specified by the system configuration parameter JobFileAppend, **defaults to 'append'** partition: request a specific partition for the resource allocation, **defaults to 'normal'** qos: request a quality of service for the job, **defaults to 'user'** requeue: specifies that the batch job should be eligible for requeuing, **defaults to 'true'** reservation: allocate resources for the job from the named reservation, **defaults to None** sockets_per_node: restrict node selection to nodes with at least the specified number of socket, **defaults to 0** spread_job: Spread the job allocation over as many nodes as possible and attempt to evenly distribute tasks across the allocated nodes (this option disables the topology/tree plugin), **defaults to 'true'** standard_error: instruct SLURM to connect the batch script's standard error directly to the file name at the specified path, **defaults to None** standard_in: instruct Slurm to connect the batch script's standard input directly to the file name at the specified path, **defaults to None** standard_out: instruct Slurm to connect the batch script's standard output directly to the file name at the specified path, **defaults to None** tasks: sbatch does not launch tasks, it requests an allocation of resources and submits a batch script. This option advises the SLURM controller that job steps run within the allocation will launch a maximum of number tasks and to provide for sufficient resources, **defaults to 1 task per node, but note that the <code>--cpus-per-task</code> option will change this default. tasks_per_core: request the maximum ntasks be invoked on each core (meant to be used with the <code>--ntasks</code> option), **defaults to 0** tasks_per_node: r that ntasks be invoked on each node (if used with the --ntasks option, the <code>--ntasks</code> option will take precedence and the <code>--ntasks-per-node</code> will be treated as a maximum count of tasks per node), **defaults to 0** tasks_per_socket: request the maximum ntasks be invoked on each socket (meant to be used with the <code>--ntasks</code> option), **defaults to 0** threads_per_core: restrict node selection to nodes with at least the specified number of threads per core. In task layout, use the specified maximum number of threads per core, **defaults to 0** time_limit: set a limit on the total run time of the job allocation, **defaults to None** wait_all_nodes: (0|1) controls when the execution of the command begins, **defaults to 0** (the job will begin execution as soon as the allocation is made) wckey: specify wckey to be used with job, **defaults to None** cores_per_socket: restrict node selection to nodes with at least the specified number of cores per socket, **defaults to None** core_specifications: count of specialized cores per node reserved by the job for system operations and not used by the application, **defaults to None** \"\"\" name : str delay_boot : Optional [ int ] = 0 # leave set to 0 dependency : Optional [ str ] = None distribution : Optional [ str ] = 'arbitrary' environment : Optional [ dict ] = None exclusive : Optional [ str ] = \"user\" get_user_environment : Optional [ str ] = None gres : Optional [ str ] = None gres_flags : Optional [ str ] = \"disable-binding\" gpu_binding : Optional [ str ] = \"closest\" gpu_frequency : Optional [ str ] = \"medium\" gpus : Optional [ str ] = None gpus_per_node : Optional [ str ] = None gpus_per_socket : Optional [ str ] = None gpus_per_task : Optional [ str ] = None hold : Optional [ str ] = 'false' licenses : Optional [ str ] = None mail_type : Optional [ str ] = \"NONE\" mail_user : Optional [ str ] = None memory_binding : Optional [ str ] = \"none\" memory_per_cpu : Optional [ str ] = 0 memory_per_gpu : Optional [ str ] = 0 memory_per_node : Optional [ str ] = 0 cpus_per_task : Optional [ int ] = 0 minimum_cpus_per_node : Optional [ str ] = 0 minimum_nodes : Optional [ str ] = 'true' nice : Optional [ str ] = None no_kill : Optional [ str ] = 'off' nodes : Optional [ int ] = 1 open_mode : Optional [ str ] = 'append' partition : Optional [ str ] = 'normal' qos : Optional [ str ] = 'user' requeue : Optional [ str ] = 'true' reservation : Optional [ str ] = None sockets_per_node : Optional [ int ] = 0 spread_job : Optional [ str ] = 'true' standard_error : Optional [ str ] = None standard_in : Optional [ str ] = None standard_out : Optional [ str ] = None tasks : Optional [ int ] = 1 tasks_per_core : Optional [ int ] = 0 tasks_per_node : Optional [ int ] = 0 tasks_per_socket : Optional [ int ] = 0 threads_per_core : Optional [ int ] = 0 time_limit : Optional [ Union [ int , str ]] = None wait_all_nodes : Optional [ str ] = 0 wckey : Optional [ str ] = None cores_per_socket : Optional [ int ] = None core_specifications : Optional [ int ] = None @validator ( 'standard_error' , 'standard_out' , 'standard_in' ) def expand_home_shortcut ( cls , v ): if v is not None : if str ( v . startswith ( '~' )): ppath = Path ( v ) return str ( ppath . expanduser ()) else : return v else : return v @validator ( 'standard_error' , 'standard_out' , 'standard_in' ) def check_abs_paths ( cls , v ): if v is not None : if not Path ( v ) . is_absolute (): return str ( Path ( env . CONTEXT_ROOT ) / v ) else : return v else : return None","title":"SLURM Jobs"},{"location":"models/slurm_job_models/#slurm-job-schemas","text":"","title":"SLURM Job Schemas"},{"location":"models/slurm_job_models/#slurmmodel","text":"Bases: BaseModel General SLURM job model including job options and the job script path, used for submitting a job through the REST API: POST job/{jobid} Attributes: Name Type Description script str full absolute path to script to be submitted as a job to the SLURM cluster job SlurmSubmit SLURM sbatch options for the associated job Source code in catena/models/slurm_submit.py 224 225 226 227 228 229 230 231 232 233 234 235 class SlurmModel ( BaseModel ): \"\"\" General SLURM job model including job options and the job script path, used for submitting a job through the REST API: <code>POST job/{jobid}</code> Attributes: script: full absolute path to script to be submitted as a job to the SLURM cluster job: SLURM sbatch options for the associated job \"\"\" script : str job : SlurmSubmit = Field ( ... )","title":"SlurmModel"},{"location":"models/slurm_job_models/#slurmsubmit","text":"Bases: ExtendedBaseModel SLURM sbatch options: see SLURM documentation for more details. Attributes: Name Type Description name str SLURM job name delay_boot Optional [ int ] do not reboot nodes in order to satisfied this job's feature specification if the job has been eligible to run for less than this time period, defaults to 0 (suggested to leave as default) dependency Optional [ str ] defer the start of this job until the specified dependencies have been satisfied completed. All dependencies must be satisfied if the ','separator is used. Dependencies are given in the format: --dependency= (list of jobids is colon-separated, indvidual dependencies are comma-separated). Any dependency may be satisfied if the \"?\" separator is used, defaults to None distribution Optional [ str ] specify alternate distribution methods for remote processes. In sbatch, this only sets environment variables that will be used by subsequent srun requests, defaults to 'arbitrary' environment Optional [ dict ] map of systems path to be set within the users environment when running the SLURM job, defaults to None exclusive Optional [ str ] The job allocation can not share nodes with other running jobs (or just other users with the '=user' option or with the '=mcs' option), defaults to 'user' get_user_environment Optional [ str ] this option will tell sbatch to retrieve the login environment variables for the user specified in the --uid option, defaults to None gres Optional [ str ] specifies a comma delimited list of generic consumable resources, defaults to None gres_flags Optional [ str ] specify generic and resource task binding options ( disable-binding/enforce-bindings ), defaults to 'disable-binding' gpu_binding Optional [ str ] bind tasks to specific GPUs. By default every spawned task can access every GPU allocated to the step, defaults to 'closest' gpu_frequency Optional [ str ] request that GPUs allocated to the job are configured with specific frequency values. This option can be used to independently configure the GPU and its memory frequencies, defaults to 'medium' gpus Optional [ str ] specify the total number of gpus required for the job ' :number', defaults to None gpus_per_node Optional [ str ] specify the number of GPUs required for the job on each node included in the job's resource allocation, defaults to None gpus_per_socket Optional [ str ] specify the number of GPUs required for the job on each socket included in the job's resource allocation. An optional GPU type specification can be supplied, defaults to None gpus_per_task Optional [ str ] specify the number of GPUs required for the job on each task to be spawned in the job's resource allocation. An optional GPU type specification can be supplied hold Optional [ str ] specify the job is to be submitted in a held state (priority of zero). A held job can now be released using scontrol to reset its priority (e.g. 'scontrol release '), defaults to false licenses Optional [ str ] specification of licenses (or other resources available on all nodes of the cluster) which must be allocated to this job. License names can be followed by a colon and count (the default count is one). Multiple license names should be comma separated (e.g. '--licenses=foo:4,bar') mail_type Optional [ str ] notify user by email when certain event types occur, defaults to 'NONE' (see SLURM documentation for full list of options) mail_user Optional [ str ] user to receive e-mail notification of state changes defined by --mail-type , defaylts as None memory_binding Optional [ str ] bind tasks to memory. Used only when the task/affinity plugin is enabled and the NUMA memory functions are available, defaults to None . memory_per_cpu Optional [ str ] minimum memory required per allocated CPU (default units are MB, different units can be specified using the suffix [K|M|G|T]), defaults to 0 memory_per_gpu Optional [ str ] minimum memory required per allocated GPU (default units are megabytes, different units can be specified using the suffix [K|M|G|T]), defaults to 0 memory_per_node Optional [ str ] specify the real memory required per node (default units are megabytes, different units can be specified using the suffix [K|M|G|T]), defaults to 0 cpus_per_task Optional [ int ] advise the SLURM controller that ensuing job steps will require ncpus number of processors per task. Without this option, the controller will just try to allocate one processor per task, defaults to 0 minimum_cpus_per_node Optional [ str ] specify a minimum number of logical cpus/processors per node, defaults to 0 minimum_nodes Optional [ str ] if a range of node counts is given, prefer the smaller count, defaults to 'true' nice Optional [ str ] run the job with an adjusted scheduling priority within Slurm. With no adjustment value the scheduling priority is decreased by 100. A negative nice value increases the priority, otherwise decreases it, defaults to None no_kill Optional [ str ] do not automatically terminate a job if one of the nodes it has been allocated fails. The user will assume the responsibilities for fault-tolerance should a node fail. When there is a node failure, any active job steps (usually MPI jobs) on that node will almost certainly suffer a fatal error, but with --no-kill , the job allocation will not be revoked so the user may launch new job steps on the remaining nodes in their allocation, defaults to 'off' nodes Optional [ int ] Request that a minimum of minnodes nodes be allocated to this job. A maximum node count may also be specified with maxnodes. If only one number is specified, this is used as both the minimum and maximum node count. The partition's node limits supersede those of the job. If a job's node limits are outside of the range permitted for its associated partition, the job will be left in a PENDING state, defaults to 1 open_mode Optional [ str ] (append|truncate) open the output and error files using append or truncate mode as specified. The default value is specified by the system configuration parameter JobFileAppend, defaults to 'append' partition Optional [ str ] request a specific partition for the resource allocation, defaults to 'normal' qos Optional [ str ] request a quality of service for the job, defaults to 'user' requeue Optional [ str ] specifies that the batch job should be eligible for requeuing, defaults to 'true' reservation Optional [ str ] allocate resources for the job from the named reservation, defaults to None sockets_per_node Optional [ int ] restrict node selection to nodes with at least the specified number of socket, defaults to 0 spread_job Optional [ str ] Spread the job allocation over as many nodes as possible and attempt to evenly distribute tasks across the allocated nodes (this option disables the topology/tree plugin), defaults to 'true' standard_error Optional [ str ] instruct SLURM to connect the batch script's standard error directly to the file name at the specified path, defaults to None standard_in Optional [ str ] instruct Slurm to connect the batch script's standard input directly to the file name at the specified path, defaults to None standard_out Optional [ str ] instruct Slurm to connect the batch script's standard output directly to the file name at the specified path, defaults to None tasks Optional [ int ] sbatch does not launch tasks, it requests an allocation of resources and submits a batch script. This option advises the SLURM controller that job steps run within the allocation will launch a maximum of number tasks and to provide for sufficient resources, **defaults to 1 task per node, but note that the --cpus-per-task option will change this default. tasks_per_core Optional [ int ] request the maximum ntasks be invoked on each core (meant to be used with the --ntasks option), defaults to 0 tasks_per_node Optional [ int ] r that ntasks be invoked on each node (if used with the --ntasks option, the --ntasks option will take precedence and the --ntasks-per-node will be treated as a maximum count of tasks per node), defaults to 0 tasks_per_socket Optional [ int ] request the maximum ntasks be invoked on each socket (meant to be used with the --ntasks option), defaults to 0 threads_per_core Optional [ int ] restrict node selection to nodes with at least the specified number of threads per core. In task layout, use the specified maximum number of threads per core, defaults to 0 time_limit Optional [ Union [ int , str ]] set a limit on the total run time of the job allocation, defaults to None wait_all_nodes Optional [ str ] (0|1) controls when the execution of the command begins, defaults to 0 (the job will begin execution as soon as wckey Optional [ str ] specify wckey to be used with job, defaults to None cores_per_socket Optional [ int ] restrict node selection to nodes with at least the specified number of cores per socket, defaults to None core_specifications Optional [ int ] count of specialized cores per node reserved by the job for system operations and not used by the application, defaults to None Source code in catena/models/slurm_submit.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 class SlurmSubmit ( ExtendedBaseModel ): \"\"\" SLURM sbatch options: see [SLURM documentation](https://slurm.schedmd.com/sbatch.html) for more details. Attributes: name: SLURM job name delay_boot: do not reboot nodes in order to satisfied this job's feature specification if the job has been eligible to run for less than this time period, **defaults to 0** (suggested to leave as default) dependency: defer the start of this job until the specified dependencies have been satisfied completed. All dependencies must be satisfied if the ','separator is used. Dependencies are given in the format: --dependency=<type:jobid[:jobid], type:jobid2[:jobid2].....> (list of jobids is colon-separated, indvidual dependencies are comma-separated). Any dependency may be satisfied if the \"?\" separator is used, **defaults to None** distribution: specify alternate distribution methods for remote processes. In sbatch, this only sets environment variables that will be used by subsequent srun requests, **defaults to 'arbitrary'** environment: map of systems path to be set within the users environment when running the SLURM job, **defaults to None** exclusive: The job allocation can not share nodes with other running jobs (or just other users with the '=user' option or with the '=mcs' option), **defaults to 'user'** get_user_environment: this option will tell sbatch to retrieve the login environment variables for the user specified in the <code>--uid</code> option, **defaults to None** gres: specifies a comma delimited list of generic consumable resources, **defaults to None** gres_flags: specify generic and resource task binding options (<code>disable-binding/enforce-bindings</code>), **defaults to 'disable-binding'** gpu_binding: bind tasks to specific GPUs. By default every spawned task can access every GPU allocated to the step, **defaults to 'closest'** gpu_frequency: request that GPUs allocated to the job are configured with specific frequency values. This option can be used to independently configure the GPU and its memory frequencies, **defaults to 'medium'** gpus: specify the total number of gpus required for the job '<type>:number', **defaults to None** gpus_per_node: specify the number of GPUs required for the job on each node included in the job's resource allocation, **defaults to None** gpus_per_socket: specify the number of GPUs required for the job on each socket included in the job's resource allocation. An optional GPU type specification can be supplied, **defaults to None** gpus_per_task: specify the number of GPUs required for the job on each task to be spawned in the job's resource allocation. An optional GPU type specification can be supplied hold: specify the job is to be submitted in a held state (priority of zero). A held job can now be released using scontrol to reset its priority (e.g. 'scontrol release <job_id>'), **defaults to false** licenses: specification of licenses (or other resources available on all nodes of the cluster) which must be allocated to this job. License names can be followed by a colon and count (the default count is one). Multiple license names should be comma separated (e.g. '--licenses=foo:4,bar') mail_type: notify user by email when certain event types occur, **defaults to 'NONE'** (see SLURM documentation for full list of options) mail_user: user to receive e-mail notification of state changes defined by <code>--mail-type</code>, **defaylts as None** memory_binding: bind tasks to memory. Used only when the task/affinity plugin is enabled and the NUMA memory functions are available, **defaults to None**. memory_per_cpu: minimum memory required per allocated CPU (default units are MB, different units can be specified using the suffix [K|M|G|T]), **defaults to 0** memory_per_gpu: minimum memory required per allocated GPU (default units are megabytes, different units can be specified using the suffix [K|M|G|T]), **defaults to 0** memory_per_node: specify the real memory required per node (default units are megabytes, different units can be specified using the suffix [K|M|G|T]), **defaults to 0** cpus_per_task: advise the SLURM controller that ensuing job steps will require ncpus number of processors per task. Without this option, the controller will just try to allocate one processor per task, **defaults to 0** minimum_cpus_per_node: specify a minimum number of logical cpus/processors per node, **defaults to 0** minimum_nodes: if a range of node counts is given, prefer the smaller count, **defaults to 'true'** nice: run the job with an adjusted scheduling priority within Slurm. With no adjustment value the scheduling priority is decreased by 100. A negative nice value increases the priority, otherwise decreases it, **defaults to None** no_kill: do not automatically terminate a job if one of the nodes it has been allocated fails. The user will assume the responsibilities for fault-tolerance should a node fail. When there is a node failure, any active job steps (usually MPI jobs) on that node will almost certainly suffer a fatal error, but with <code>--no-kill</code>, the job allocation will not be revoked so the user may launch new job steps on the remaining nodes in their allocation, **defaults to 'off'** nodes: Request that a minimum of minnodes nodes be allocated to this job. A maximum node count may also be specified with maxnodes. If only one number is specified, this is used as both the minimum and maximum node count. The partition's node limits supersede those of the job. If a job's node limits are outside of the range permitted for its associated partition, the job will be left in a PENDING state, **defaults to 1** open_mode: (append|truncate) open the output and error files using append or truncate mode as specified. The default value is specified by the system configuration parameter JobFileAppend, **defaults to 'append'** partition: request a specific partition for the resource allocation, **defaults to 'normal'** qos: request a quality of service for the job, **defaults to 'user'** requeue: specifies that the batch job should be eligible for requeuing, **defaults to 'true'** reservation: allocate resources for the job from the named reservation, **defaults to None** sockets_per_node: restrict node selection to nodes with at least the specified number of socket, **defaults to 0** spread_job: Spread the job allocation over as many nodes as possible and attempt to evenly distribute tasks across the allocated nodes (this option disables the topology/tree plugin), **defaults to 'true'** standard_error: instruct SLURM to connect the batch script's standard error directly to the file name at the specified path, **defaults to None** standard_in: instruct Slurm to connect the batch script's standard input directly to the file name at the specified path, **defaults to None** standard_out: instruct Slurm to connect the batch script's standard output directly to the file name at the specified path, **defaults to None** tasks: sbatch does not launch tasks, it requests an allocation of resources and submits a batch script. This option advises the SLURM controller that job steps run within the allocation will launch a maximum of number tasks and to provide for sufficient resources, **defaults to 1 task per node, but note that the <code>--cpus-per-task</code> option will change this default. tasks_per_core: request the maximum ntasks be invoked on each core (meant to be used with the <code>--ntasks</code> option), **defaults to 0** tasks_per_node: r that ntasks be invoked on each node (if used with the --ntasks option, the <code>--ntasks</code> option will take precedence and the <code>--ntasks-per-node</code> will be treated as a maximum count of tasks per node), **defaults to 0** tasks_per_socket: request the maximum ntasks be invoked on each socket (meant to be used with the <code>--ntasks</code> option), **defaults to 0** threads_per_core: restrict node selection to nodes with at least the specified number of threads per core. In task layout, use the specified maximum number of threads per core, **defaults to 0** time_limit: set a limit on the total run time of the job allocation, **defaults to None** wait_all_nodes: (0|1) controls when the execution of the command begins, **defaults to 0** (the job will begin execution as soon as the allocation is made) wckey: specify wckey to be used with job, **defaults to None** cores_per_socket: restrict node selection to nodes with at least the specified number of cores per socket, **defaults to None** core_specifications: count of specialized cores per node reserved by the job for system operations and not used by the application, **defaults to None** \"\"\" name : str delay_boot : Optional [ int ] = 0 # leave set to 0 dependency : Optional [ str ] = None distribution : Optional [ str ] = 'arbitrary' environment : Optional [ dict ] = None exclusive : Optional [ str ] = \"user\" get_user_environment : Optional [ str ] = None gres : Optional [ str ] = None gres_flags : Optional [ str ] = \"disable-binding\" gpu_binding : Optional [ str ] = \"closest\" gpu_frequency : Optional [ str ] = \"medium\" gpus : Optional [ str ] = None gpus_per_node : Optional [ str ] = None gpus_per_socket : Optional [ str ] = None gpus_per_task : Optional [ str ] = None hold : Optional [ str ] = 'false' licenses : Optional [ str ] = None mail_type : Optional [ str ] = \"NONE\" mail_user : Optional [ str ] = None memory_binding : Optional [ str ] = \"none\" memory_per_cpu : Optional [ str ] = 0 memory_per_gpu : Optional [ str ] = 0 memory_per_node : Optional [ str ] = 0 cpus_per_task : Optional [ int ] = 0 minimum_cpus_per_node : Optional [ str ] = 0 minimum_nodes : Optional [ str ] = 'true' nice : Optional [ str ] = None no_kill : Optional [ str ] = 'off' nodes : Optional [ int ] = 1 open_mode : Optional [ str ] = 'append' partition : Optional [ str ] = 'normal' qos : Optional [ str ] = 'user' requeue : Optional [ str ] = 'true' reservation : Optional [ str ] = None sockets_per_node : Optional [ int ] = 0 spread_job : Optional [ str ] = 'true' standard_error : Optional [ str ] = None standard_in : Optional [ str ] = None standard_out : Optional [ str ] = None tasks : Optional [ int ] = 1 tasks_per_core : Optional [ int ] = 0 tasks_per_node : Optional [ int ] = 0 tasks_per_socket : Optional [ int ] = 0 threads_per_core : Optional [ int ] = 0 time_limit : Optional [ Union [ int , str ]] = None wait_all_nodes : Optional [ str ] = 0 wckey : Optional [ str ] = None cores_per_socket : Optional [ int ] = None core_specifications : Optional [ int ] = None @validator ( 'standard_error' , 'standard_out' , 'standard_in' ) def expand_home_shortcut ( cls , v ): if v is not None : if str ( v . startswith ( '~' )): ppath = Path ( v ) return str ( ppath . expanduser ()) else : return v else : return v @validator ( 'standard_error' , 'standard_out' , 'standard_in' ) def check_abs_paths ( cls , v ): if v is not None : if not Path ( v ) . is_absolute (): return str ( Path ( env . CONTEXT_ROOT ) / v ) else : return v else : return None","title":"SlurmSubmit"},{"location":"slurmapi/","text":"","title":"Index"}]}